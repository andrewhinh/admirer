{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import boto3  # boto3: high-level API\n",
    "import random\n",
    "import language_tool_python\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from botocore import UNSIGNED  # botocore: lower-level API and components\n",
    "from botocore.config import Config\n",
    "from IPython.display import Image\n",
    "from pyngrok import ngrok\n",
    "from onnxruntime import InferenceSession\n",
    "from transformers import CLIPProcessor\n",
    "from typing import Optional\n",
    "\n",
    "from question_answer.metadata.shared import DATA_DIRNAME, DOWNLOADED_DATA_DIRNAME\n",
    "\n",
    "tool = language_tool_python.LanguageTool('en-US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACT_PATH = \"../question_answer/artifacts/answer/\"\n",
    "ANN_PATH = ARTIFACT_PATH + \"coco_annotations/\"\n",
    "CAPTIONS = ANN_PATH + \"captions_train2014.json\"\n",
    "PREPROCESSED = ANN_PATH + \"admirer-pica.json\"\n",
    "\n",
    "SIMILARITY_PATH = ARTIFACT_PATH + \"coco_clip_new/\"\n",
    "IDXS = SIMILARITY_PATH + \"okvqa_qa_line2sample_idx_train2014.json\"\n",
    "QUESTION_FEATURES = SIMILARITY_PATH + \"coco_clip_vitb16_train2014_okvqa_question.npy\"\n",
    "IMG_FEATURES = SIMILARITY_PATH + \"coco_clip_vitb16_train2014_okvqa_convertedidx_image.npy\"\n",
    "\n",
    "clip_processor = ARTIFACT_PATH + \"transformers/openai/clip-vit-base-patch16\"\n",
    "clip_onnx = ARTIFACT_PATH + \"onnx/clip.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install great_expectations s3 dash -y\n",
    "\n",
    "!zenml artifact-store register s3_great_expectations \\\n",
    "    --flavor=s3 \\\n",
    "    --path=s3://admirer-pica-zenml-greatexpectations # Register S3 bucket allowing ZenML write access\n",
    "\n",
    "!zenml data-validator register great_expectations \\\n",
    "    --flavor=great_expectations\n",
    "\n",
    "!zenml stack register admirer-great-expectations \\\n",
    "    -o default \\\n",
    "    -a s3_great_expectations \\\n",
    "    -dv great_expectations \\\n",
    "    --set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.checkpoint.types.checkpoint_result import (  # type: ignore[import]\n",
    "    CheckpointResult,\n",
    ")\n",
    "\n",
    "from zenml.integrations.constants import GREAT_EXPECTATIONS, SKLEARN\n",
    "from zenml.integrations.great_expectations.steps import (\n",
    "    GreatExpectationsProfilerParameters,\n",
    "    GreatExpectationsProfilerStep,\n",
    "    GreatExpectationsValidatorParameters,\n",
    "    GreatExpectationsValidatorStep,\n",
    ")\n",
    "from zenml.integrations.great_expectations.visualizers import (\n",
    "    GreatExpectationsVisualizer,\n",
    ")\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import BaseParameters, Output, step\n",
    "\n",
    "\n",
    "from zenml.steps import (\n",
    "    STEP_ENVIRONMENT_NAME,\n",
    "    StepEnvironment,\n",
    ")\n",
    "from zenml.environment import Environment\n",
    "from typing import cast\n",
    "\n",
    "\n",
    "from zenml.config import DockerSettings\n",
    "\n",
    "\n",
    "from zenml.post_execution import get_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket_name = \"admirer-pica\"  # objects are placed into buckets\n",
    "s3_directory_path = \"images\"  # buckets can contain \"folders\" for organization\n",
    "# we combine this information into a base URL format for the data:\n",
    "s3_url = f\"https://{s3_bucket_name}.s3.us-west-1.amazonaws.com/{s3_directory_path}\"\n",
    "s3_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_idx = 1\n",
    "image_idx = 1\n",
    "img_url = f\"{s3_url}/{str(person_idx).zfill(3)}_{str(image_idx).zfill(2)}.png\"\n",
    "print(img_url)\n",
    "Image(url=img_url, width=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADMIRER_RAW_DATA_DIRNAME = DATA_DIRNAME / \"raw\" / s3_bucket_name\n",
    "ADMIRER_DL_DATA_DIRNAME = DOWNLOADED_DATA_DIRNAME / s3_bucket_name / s3_directory_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spin up a client for communicating with s3 without authenticating (\"UNSIGNED\" activity)\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "!mkdir -p {ADMIRER_DL_DATA_DIRNAME}\n",
    "\n",
    "s3.download_file(\n",
    "    s3_bucket_name, s3_directory_path + \"/001_01.png\", f\"{ADMIRER_DL_DATA_DIRNAME}/001_01.png\")\n",
    "\n",
    "Image(filename=f\"{ADMIRER_DL_DATA_DIRNAME}/001_01.png\", width=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = boto3.resource('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "\n",
    "def download_s3_folder(bucket_name: str, s3_folder: str, local_dir: Optional[str] = None):\n",
    "    \"\"\"Download the contents of a folder on S3, recursively.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bucket_name: the name of the s3 bucket\n",
    "    s3_folder: the folder path in the s3 bucket\n",
    "    local_dir: a relative or absolute directory path in the local file system\n",
    "    \"\"\"\n",
    "    # from https://stackoverflow.com/questions/49772151/download-a-folder-from-s3-using-boto3\n",
    "    bucket = s3_resource.Bucket(bucket_name)\n",
    "    for obj in bucket.objects.filter(Prefix=s3_folder):\n",
    "        target = obj.key if local_dir is None \\\n",
    "            else os.path.join(local_dir, os.path.relpath(obj.key, s3_folder))\n",
    "        if not os.path.exists(os.path.dirname(target)):\n",
    "            os.makedirs(os.path.dirname(target))\n",
    "        if obj.key[-1] == '/':\n",
    "            continue\n",
    "        bucket.download_file(obj.key, target)\n",
    "        \n",
    "        \n",
    "download_s3_folder(s3_bucket_name, s3_directory_path, ADMIRER_DL_DATA_DIRNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find {ADMIRER_DL_DATA_DIRNAME} | head -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Annotation\n",
    "- Note: not used since annotations obtained with Scale.ai, but here for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring and connecting to the web server\n",
    "- In some cases, you might have to sign up for an account and use that to login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"admirer@localhost\"\n",
    "password = \"moonshine\"\n",
    "\n",
    "%env LABEL_STUDIO_USERNAME={username}\n",
    "%env LABEL_STUDIO_PASSWORD={password}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = ngrok.conf.DEFAULT_NGROK_CONFIG_PATH\n",
    "config_file_exists =  os.path.exists(config_file)\n",
    "config_file_contents = !cat {config_file}\n",
    "\n",
    "auth_token_found = config_file_exists \\\n",
    "    and config_file_contents \\\n",
    "    and \"authtoken\" in config_file_contents[0] \\\n",
    "    and \": exit\" not in config_file_contents  # state if interrupted\n",
    "\n",
    "if not auth_token_found:\n",
    "    print(\"Enter your ngrok auth token, which can be copied from https://dashboard.ngrok.com/auth\")\n",
    "    !ngrok authtoken {getpass.getpass()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_STUDIO_PORT = 8081\n",
    "%env LABEL_STUDIO_PORT={LABEL_STUDIO_PORT}\n",
    "\n",
    "https_tunnel = ngrok.connect(LABEL_STUDIO_PORT, bind_tls=True)\n",
    "print(https_tunnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this in the terminal\n",
    "\"\"\"\n",
    "python3 -m venv label-env \\ \n",
    "    conda deactivate \\\n",
    "    source label-env/bin/activate \\\n",
    "    pip install -qqq label-studio \\\n",
    "    export LABEL_STUDIO_PORT=8081 \\\n",
    "    label-studio start --port=$LABEL_STUDIO_PORT \\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(https_tunnel.public_url)\n",
    "print(\"u:\", username)\n",
    "print(\"p:\", password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_urls = []\n",
    "for person_idx in range(1, 104):\n",
    "    for image_idx in range(1, 13):\n",
    "        img_urls.append(f\"{s3_url}/{str(person_idx).zfill(3)}_{str(image_idx).zfill(2)}.png\")\n",
    "len(img_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(img_urls, columns=[\"webcam\"])\n",
    "df.to_csv(str(ADMIRER_RAW_DATA_DIRNAME / \"manifest.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ADMIRER_RAW_DATA_DIRNAME / \"manifest.csv\")\n",
    "!cat {ADMIRER_RAW_DATA_DIRNAME}/manifest.csv | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teardown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in the terminal\n",
    "\"\"\"\n",
    "deactivate /\n",
    "    conda activate admirer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "- Depends on Annotation Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LabelStudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ADMIRER_RAW_DATA_DIRNAME / \"annotated_data.json\", \"r\") as f: data = json.load(f)\n",
    "\n",
    "ids = data['id']\n",
    "s3_links = data['webcam']\n",
    "captions = data['caption']\n",
    "list_tags = data['tags']\n",
    "questions = data['question']\n",
    "answers = data['answer']\n",
    "\n",
    "ids[0], s3_links[0], captions[0], list_tags[0], questions[0], answers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "s3_filenames = []\n",
    "captions = []\n",
    "list_tags = []\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "with open(ADMIRER_RAW_DATA_DIRNAME / \"annotated_data.json\", \"r\") as f: data = json.load(f)\n",
    "for task in data: \n",
    "    ids.append(task['task_id'])\n",
    "    s3_filenames.append(task['metadata']['filename'])\n",
    "    temp = task['response']['global_attributes']\n",
    "    captions.append(temp['caption'])\n",
    "    list_tags.append(temp['tags'])\n",
    "    questions.append(temp['question'])\n",
    "    answers.append(temp['answer'])\n",
    "\n",
    "ids[0], s3_filenames[0], captions[0], list_tags[0], questions[0], answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to convert s3_filenames -> img_urls to save to df\n",
    "s3_filenames[0], img_urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_urls is sorted, so we save the sorted filenames and pull the url for the corresponding filename\n",
    "ordered_filenames = sorted(s3_filenames)[0]\n",
    "ordered_filenames[0], img_urls[ordered_filenames.index(s3_filenames[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_links = [img_urls[ordered_filenames.index(s3_filenames[id])] for id in range(len(img_urls))]\n",
    "s3_links[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct Grammar Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = [tool.correct(caption).strip().strip(\"\\n\").strip(\".\") for caption in captions]\n",
    "list_tags = [tool.correct(tag).strip().strip(\"\\n\").strip(\".\") for tag in list_tags]\n",
    "questions = [tool.correct(question).strip().strip(\"\\n\") for question in questions]\n",
    "answers = [tool.correct(answer).strip().strip(\"\\n\").strip(\".\") for answer in answers]\n",
    "\n",
    "func = lambda s: s[:1].lower() + s[1:] if s else ''\n",
    "list_tags = [func(tag) for tag in list_tags]\n",
    "answers = [func(answer) for answer in answers]\n",
    "\n",
    "captions[0], list_tags[0], questions[0], answers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding image and question id columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = []\n",
    "\n",
    "coco_caption = json.load(open(CAPTIONS, \"r\"))\n",
    "if isinstance(coco_caption, dict):\n",
    "    coco_caption = coco_caption[\"annotations\"]\n",
    "for sample in coco_caption:\n",
    "    if sample[\"image_id\"] not in keys: keys.append(sample[\"image_id\"])      \n",
    "\n",
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = []\n",
    "question_ids = []\n",
    "num_gen = 0\n",
    "\n",
    "while num_gen<len(df):\n",
    "    rand_num = random.randint(10000, 999999)\n",
    "    if rand_num not in keys:\n",
    "        image_ids.append(rand_num)\n",
    "        question_ids.append(str(rand_num) + '5')\n",
    "        num_gen+=1\n",
    "        \n",
    "print(len(df), len(image_ids), len(question_ids), image_ids[0], question_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(image_ids,\n",
    "                           question_ids,\n",
    "                           s3_links,\n",
    "                           captions,\n",
    "                           list_tags,\n",
    "                           questions,\n",
    "                           answers)), columns=[\"image_id\",\n",
    "                                               \"question_id\",\n",
    "                                               \"webcam\",\n",
    "                                               \"caption\",\n",
    "                                               \"tags\",\n",
    "                                               \"question\",\n",
    "                                               \"answer\"])\n",
    "df.to_json(PREPROCESSED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Idxs + Feature Artifact Files (coco_clip_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = json.load(\n",
    "    open(\n",
    "        IDXS,\n",
    "        \"r\",\n",
    "    )\n",
    ")\n",
    "train_feature = np.load(QUESTION_FEATURES)\n",
    "image_train_feature = np.load(\n",
    "    IMG_FEATURES\n",
    ")\n",
    "train_feature.shape, len(train_idx), image_train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_ids = [str(image_id) + \"<->\" + str(question_id) for image_id, question_id in zip(list(df['image_id']), list(df['question_id']))]\n",
    "num_idx = list(range(9009, 9009+len(df)))\n",
    "num_idx = list(map(str, num_idx))\n",
    "idx_add = dict(zip(num_idx, combine_ids))\n",
    "train_idx.update(idx_add)\n",
    "len(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_session = InferenceSession(str(clip_onnx))\n",
    "clip_processor = CLIPProcessor.from_pretrained(clip_processor)\n",
    "\n",
    "data_path = DOWNLOADED_DATA_DIRNAME / \"admirer-pica/images/\"\n",
    "images = [str(data_path / f) for f in os.listdir(str(data_path)) if os.path.isfile(os.path.join(str(data_path),f))]\n",
    "images_pil = []\n",
    "\n",
    "for image in images:\n",
    "    image_pil = Image.open(image)\n",
    "    if image_pil.mode != \"RGB\":\n",
    "        image_pil = image_pil.convert(mode=\"RGB\")\n",
    "    images_pil.append(image_pil)\n",
    "   \n",
    "inputs = clip_processor(text=list(df['question']), images=images_pil, return_tensors=\"np\", padding=True)\n",
    "outputs = clip_session.run(\n",
    "    output_names=[\"logits_per_image\", \"logits_per_text\", \"text_embeds\", \"image_embeds\"], input_feed=dict(inputs)\n",
    ")\n",
    "\n",
    "train_feature = np.concatenate((train_feature, outputs[2]))\n",
    "image_train_feature = np.concatenate((image_train_feature, outputs[3]))\n",
    "train_feature.shape, image_train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(IDXS, \"w\") as f: json.dump(train_idx, f)\n",
    "with open(QUESTION_FEATURES, 'wb') as f: np.save(f, train_feature)\n",
    "with open(IMG_FEATURES, 'wb') as f: np.save(f, image_train_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ZenML Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderParameters(BaseParameters):\n",
    "    reference_data: bool = True\n",
    "\n",
    "@step\n",
    "def importer(\n",
    "        params: DataLoaderParameters,\n",
    ") -> Output(dataset=pd.DataFrame, condition=bool):\n",
    "    # Load labeled projects\n",
    "    df = pd.read_json(PREPROCESSED)\n",
    "    return df, params.reference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a builtin Great Expectations data profiling step\n",
    "ge_profiler_params = GreatExpectationsProfilerParameters(\n",
    "    expectation_suite_name=\"admirer-pica\",\n",
    "    data_asset_name=\"admirer-pica_test_df\",\n",
    ")\n",
    "ge_profiler_step = GreatExpectationsProfilerStep(params=ge_profiler_params)\n",
    "\n",
    "\n",
    "# instantiate a builtin Great Expectations data validation step\n",
    "ge_validator_params = GreatExpectationsValidatorParameters(\n",
    "    expectation_suite_name=\"admirer-pica\",\n",
    "    data_asset_name=\"admirer-pica_test_df\",\n",
    ")\n",
    "ge_validator_step = GreatExpectationsValidatorStep(params=ge_validator_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def analyze_result(\n",
    "    result: CheckpointResult,\n",
    ") -> str:\n",
    "    \"\"\"Analyze the Great Expectations validation result and return a true/false value indicating\n",
    "    whether it passed or failed.\"\"\"\n",
    "    step_env = cast(StepEnvironment, Environment()[STEP_ENVIRONMENT_NAME])\n",
    "    pipeline_name = step_env.pipeline_name\n",
    "    pipeline_run_id = step_env.pipeline_run_id\n",
    "    step_name = step_env.step_name\n",
    "    pipeline_context = f\"Pipeline {pipeline_name}, with run {pipeline_run_id}, in step {step_name} produced the following output:\\n\\n\"\n",
    "    if result.success:\n",
    "        message = pipeline_context + \"Great Expectations data validation was successful!\"\n",
    "    else:\n",
    "        message = pipeline_context + \"Great Expectations data validation failed!\"\n",
    "    print(message)\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ZenML Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_settings = DockerSettings(required_integrations=[GREAT_EXPECTATIONS])\n",
    "\n",
    "@pipeline(enable_cache=False, settings={\"docker\": docker_settings})\n",
    "def profiling_pipeline(\n",
    "    importer, profiler\n",
    "):\n",
    "    \"\"\"Data profiling pipeline for Great Expectations.\n",
    "\n",
    "    The pipeline imports a reference dataset from a source then uses the builtin\n",
    "    Great Expectations profiler step to generate an expectation suite (i.e.\n",
    "    validation rules) inferred from the schema and statistical properties of the\n",
    "    reference dataset.\n",
    "\n",
    "    Args:\n",
    "        importer: reference data importer step\n",
    "        profiler: data profiler step\n",
    "    \"\"\"\n",
    "    dataset, _ = importer()\n",
    "    profiler(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(enable_cache=False, settings={\"docker\": docker_settings})\n",
    "def validation_pipeline(\n",
    "    importer, validator, checker\n",
    "):\n",
    "    \"\"\"Data validation pipeline for Great Expectations.\n",
    "\n",
    "    The pipeline imports a test data from a source, then uses the builtin\n",
    "    Great Expectations data validation step to validate the dataset against\n",
    "    the expectation suite generated in the profiling pipeline.\n",
    "\n",
    "    Args:\n",
    "        importer: test data importer step\n",
    "        validator: dataset validation step\n",
    "        checker: checks the validation results\n",
    "    \"\"\"\n",
    "    dataset, condition = importer()\n",
    "    results = validator(dataset, condition)\n",
    "    message = checker(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiling_pipeline(\n",
    "    importer=importer(params=DataLoaderParameters(reference_data=True)),\n",
    "    profiler=ge_profiler_step,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_pipeline(\n",
    "    importer=importer(params=DataLoaderParameters(reference_data=True)),\n",
    "    validator=ge_validator_step,\n",
    "    checker=analyze_result(),\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post execution workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_pipeline_visualizer(name: str):\n",
    "\n",
    "    from zenml.integrations.dash.visualizers.pipeline_run_lineage_visualizer import (\n",
    "        PipelineRunLineageVisualizer,\n",
    "    )\n",
    "\n",
    "    latest_run = get_pipeline(name).runs[-1]\n",
    "    PipelineRunLineageVisualizer().visualize(latest_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(pipeline_name: str, step_name: str) -> None:\n",
    "    pipeline = get_pipeline(pipeline_name)\n",
    "    last_run = pipeline.runs[-1]\n",
    "    step = last_run.get_step(step=step_name)\n",
    "    GreatExpectationsVisualizer().visualize(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_pipeline_visualizer(\"profiling_pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_pipeline_visualizer(\"validation_pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_results(\"profiling_pipeline\", \"profiler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_results(\"validation_pipeline\", \"validator\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('admirer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c4de3d17692a4fce36158e1e6b4cc65d2c1c1dbb8a445fcd77e7a07c1299f79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
