{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlH0lCOttCs5"
   },
   "source": [
    "<img src=\"https://fsdl.me/logo-720-dark-horizontal\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUPRHaeetRnT"
   },
   "source": [
    "# Lab 06: Data Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bry3Hr-PcgDs"
   },
   "source": [
    "### What You Will Learn\n",
    "\n",
    "- How the `IAM` handwriting dataset is structured on disk and how it is processed into an ML-friendly format\n",
    "- How to setup a [Label Studio](https://labelstud.io/) data annotation server\n",
    "- Just how messy data really is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vs0LXXlCU6Ix"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZkQiK7lkgeXm"
   },
   "source": [
    "If you're running this notebook on Google Colab,\n",
    "the cell below will run full environment setup.\n",
    "\n",
    "It should take about three minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVx7C7H0PIZC"
   },
   "outputs": [],
   "source": [
    "lab_idx = 6\n",
    "\n",
    "\n",
    "if \"bootstrap\" not in locals() or bootstrap.run:\n",
    "    # path management for Python\n",
    "    pythonpath, = !echo $PYTHONPATH\n",
    "    if \".\" not in pythonpath.split(\":\"):\n",
    "        pythonpath = \".:\" + pythonpath\n",
    "        %env PYTHONPATH={pythonpath}\n",
    "        !echo $PYTHONPATH\n",
    "\n",
    "    # get both Colab and local notebooks into the same state\n",
    "    !wget --quiet https://fsdl.me/gist-bootstrap -O bootstrap.py\n",
    "    import bootstrap\n",
    "\n",
    "    # change into the lab directory\n",
    "    bootstrap.change_to_lab_dir(lab_idx=lab_idx)\n",
    "\n",
    "    # needed for inline plots in some contexts\n",
    "    %matplotlib inline\n",
    "\n",
    "    bootstrap.run = False  # change to True re-run setup\n",
    "    \n",
    "!pwd\n",
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow along with a video walkthrough on YouTube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "\n",
    "IFrame(src=\"https://fsdl.me/2022-lab-06-video-embed\", width=\"100%\", height=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTkKzEMNR8XZ"
   },
   "source": [
    "# `IAMParagraphs`: From annotated data to a PyTorch `Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mQLbjuiwZuj"
   },
   "source": [
    "We've used the `text_recognizer.data` submodule\n",
    "and its `LightningDataModule`s -- `IAMLines` and `IAMParagraphs`\n",
    "for lines and paragraphs of handwritten text\n",
    "from the\n",
    "[IAM Handwriting Database](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database).\n",
    "\n",
    "These classes convert data from a database-friendly format\n",
    "designed for storage and transfer into the\n",
    "format our DNNs expect:\n",
    "PyTorch `Tensor`s.\n",
    "\n",
    "In this section,\n",
    "we'll walk through that process in detail.\n",
    "\n",
    "In the following section,\n",
    "we'll see how data\n",
    "goes from signals measured in the world\n",
    "to the format we consume here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "499c23a6"
   },
   "source": [
    "## Dataset structure on disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3438d2e"
   },
   "source": [
    "We begin by downloading the raw data to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18900eec"
   },
   "outputs": [],
   "source": [
    "from text_recognizer.data.iam import IAM\n",
    "\n",
    "iam = IAM()\n",
    "iam.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a332f359"
   },
   "source": [
    "The `IAM` dataset is downloaded as zip file\n",
    "and then unzipped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6c44266"
   },
   "outputs": [],
   "source": [
    "from text_recognizer.metadata.iam import DL_DATA_DIRNAME\n",
    "\n",
    "\n",
    "iam_dir = DL_DATA_DIRNAME\n",
    "!ls {iam_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8463c2d1"
   },
   "source": [
    "The unzipped dataset is not simple a flat directory of files.\n",
    "\n",
    "Instead, there are a number of subfolders,\n",
    "each of which contains a particular type of data or metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "536924f7"
   },
   "outputs": [],
   "source": [
    "iamdb = iam_dir / \"iamdb\"\n",
    "\n",
    "!du -h {iamdb}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b745a594"
   },
   "source": [
    "For example, the `task` folder contains metadata about canonical dataset splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84c21f75"
   },
   "outputs": [],
   "source": [
    "!find {iamdb / \"task\"} | grep \"\\\\.txt$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEb0Pdm4vIHe"
   },
   "source": [
    "We find the images of handwritten text in the `forms` folder.\n",
    "\n",
    "An individual \"datapoint\" in `IAM` is a \"form\",\n",
    "because the humans whose hands wrote the text were prompted to write on \"forms\",\n",
    "as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "945d5e3a"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "form_fn, = !find {iamdb}/forms | grep \".jpg$\" | sort | head -n 1\n",
    "\n",
    "print(form_fn)\n",
    "Image(filename=form_fn, width=\"360\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9e9e384"
   },
   "source": [
    "Meanwhile, the `xml` files contain the data annotations,\n",
    "written out as structured text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6add5c5a"
   },
   "outputs": [],
   "source": [
    "xml_fn, = !find {iamdb}/xml | grep \"\\.xml$\" | sort | head -n 1\n",
    "\n",
    "!cat {xml_fn} | grep -A 100 \"handwritten-part\" | grep \"<word\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQOrOeDmvIHf"
   },
   "source": [
    "Make sure to correlate the `text` field of the XML to the image above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9rJgvgktg1h"
   },
   "source": [
    "## Extracting paragraphs from raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44XunBUsvIHg"
   },
   "source": [
    "The raw jpg images and XML labels are not sufficient to train a text recognition model.\n",
    "\n",
    "That's because the images do not resemble the images we expect users to submit,\n",
    "for example beause the handwritten text is always paired\n",
    "with printed text with (nearly) identical content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64d3389c"
   },
   "source": [
    "Luckily, the XML files contain the position metadata required\n",
    "to convert images of entire forms into more useful images,\n",
    "e.g. of lines or paragraphs of handwritten text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b063e7bb"
   },
   "outputs": [],
   "source": [
    "xml_fn, = !find {iamdb}/xml | grep \"\\.xml$\" | sort | head -n 1\n",
    "\n",
    "!cat {xml_fn} | grep -A 25 \"handwritten-part\" | grep -A 5 \"<word\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXS1xs8Luy3Z"
   },
   "source": [
    "So from images of entire forms, as below,\n",
    "and XML position and label metadata,\n",
    "we need to extract cropped images\n",
    "of paragraphs and string labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fa0tgKLtu_8"
   },
   "outputs": [],
   "source": [
    "import text_recognizer.util as util\n",
    "\n",
    "form_id = \"g01-031\"\n",
    "fn = iam.form_filenames_by_id[form_id]\n",
    "\n",
    "print(fn)\n",
    "Image(filename=fn, width=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMkPvR5guy3Z"
   },
   "source": [
    "This is handled by a utility function, `get_paragraph_crops_and_labels`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUiwbprWtq4f"
   },
   "outputs": [],
   "source": [
    "from text_recognizer.data.iam_paragraphs import get_paragraph_crops_and_labels\n",
    "\n",
    "p_crops, p_labels = get_paragraph_crops_and_labels(iam, split=\"val\")\n",
    "\n",
    "print(p_labels[form_id])\n",
    "p_crops[form_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ns39ag8YvfYB"
   },
   "source": [
    "The labels are directly available from the XML.\n",
    "\n",
    "The spatial extents of lines are also directly available from the XML,\n",
    "as the coordinates of the top-right and bottom-left corners of boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNVYKFp0uy3a"
   },
   "outputs": [],
   "source": [
    "from text_recognizer.data.iam import _get_line_regions_from_xml_file\n",
    "\n",
    "_get_line_regions_from_xml_file??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r08FGTHPvIHi"
   },
   "source": [
    "And we \"join\" the spatial extents of the lines together to cover paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSggKKjMuy3a"
   },
   "source": [
    "There are two other pre-processing steps here:\n",
    "\n",
    "- We resize them so they take up less memory.\n",
    "- We invert them because many NNs work better\n",
    "with positive features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sz377cIs5LtO"
   },
   "source": [
    "## Structuring into a PyTorch dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqC0jTKm5KQa"
   },
   "source": [
    "Lastly, we convert to something we can use with PyTorch and `torchvision`: a PyTorch `Dataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1y4jUPe5-bR"
   },
   "source": [
    "A basic `Dataset` just allows us to index into multiple sources of data\n",
    "(e.g. the inputs and the targets) at the same time,\n",
    "via their `__getitem__` method.\n",
    "\n",
    "This may seem simple -- how hard could it be to keep some indices aligned? --\n",
    "but consider that PyTorch `Dataset`s implement e.g.\n",
    "subsetting and shuffling.\n",
    "\n",
    "Let's look at the `BaseDataset` class we use in the FSDL codebase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KOoCZMhvIHj"
   },
   "outputs": [],
   "source": [
    "from text_recognizer.data.util import BaseDataset\n",
    "\n",
    "\n",
    "BaseDataset.__getitem__??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHSUtgP7vIHk"
   },
   "source": [
    "Notice that while indexing into data, the `Dataset` can also perform computations.\n",
    "\n",
    "When using `DataLoader`s with multi-processing,\n",
    "i.e. setting the `num_workers` arugment to `1` or more,\n",
    "these computations are done in a separate process.\n",
    "\n",
    "So our input images,\n",
    "which we might want to edit via data augmentation,\n",
    "are just kept as a list of `PIL` images,\n",
    "to be turned into `Tensor`s by the `self.transforms` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QuCODqWA5ZPF"
   },
   "outputs": [],
   "source": [
    "list_crops = list(p_crops.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChxcWzKvvIHk"
   },
   "source": [
    "We don't intend to apply any transformations to our targets,\n",
    "so we just convert them to `Tensor`s now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J67-NACg3biT"
   },
   "outputs": [],
   "source": [
    "from text_recognizer.data.util import convert_strings_to_labels\n",
    "from text_recognizer.data import IAMParagraphs\n",
    "\n",
    "iam_paragraphs = IAMParagraphs()\n",
    "\n",
    "tensor_labels = convert_strings_to_labels(\n",
    "    strings=p_labels.values(),\n",
    "    mapping=iam_paragraphs.inverse_mapping,\n",
    "    length=iam_paragraphs.output_dims[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUGNL7-F6cHq"
   },
   "source": [
    "Once we combine these together with a `BaseDataset`,\n",
    "we're ready to feed data into our neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMPgGl4a3BUL",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "dataset = BaseDataset(list_crops, tensor_labels, transform=ToTensor())\n",
    "\n",
    "im, label = dataset[0]\n",
    "\n",
    "im, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_krdrSIwO6B"
   },
   "source": [
    "## Synthesizing handwritten paragraphs from handwritten lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jL-JUwuSvIHl"
   },
   "source": [
    "The finer-grained the annotations we have for our images,\n",
    "the more useful our data can be.\n",
    "\n",
    "For example,\n",
    "the IAM dataset on its own is quite small.\n",
    "The total number of forms, and hence paragraphs, is only ~1500.\n",
    "\n",
    "However, we know that each paragraph is made by stitching together sequential lines\n",
    "from a single form.\n",
    "\n",
    "We can create a functionally infinite source of additional synthetic paragraphs\n",
    "by stitching together lines from different forms and without regard to order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbVAjMw5vIHl"
   },
   "source": [
    "Since the `__getitem__` method of a `Dataset` runs in a separate process\n",
    "and is allowed to transform data,\n",
    "we can, with care,\n",
    "just generate the data on the fly inside that method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZ5mQsCmvIHl"
   },
   "outputs": [],
   "source": [
    "from text_recognizer.data.iam_synthetic_paragraphs import IAMSyntheticParagraphsDataset\n",
    "\n",
    "\n",
    "IAMSyntheticParagraphsDataset.__getitem__??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVQ_KkIovIHl"
   },
   "outputs": [],
   "source": [
    "import wandb  # for the convenient method to visualize Tensors as images\n",
    "\n",
    "from text_recognizer.data import IAMSyntheticParagraphs\n",
    "\n",
    "iam_synthetic_paragraphs = IAMSyntheticParagraphs()\n",
    "\n",
    "iam_synthetic_paragraphs.prepare_data()\n",
    "iam_synthetic_paragraphs.setup()\n",
    "\n",
    "\n",
    "wandb.Image(iam_synthetic_paragraphs.data_train[0][0]).image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lmti54lQvIHm"
   },
   "source": [
    "This additional synthetic data doesn't quite look like\n",
    "the real data we expect to see in production,\n",
    "nor is it entirely different from the data we already collected,\n",
    "but it's sufficient to help our model learn better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tsEMCLsv_39"
   },
   "source": [
    "# FSDL Handwriting Dataset: From images to an annotated dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6wZUgndGwPb"
   },
   "source": [
    "Above, we relied on an existing dataset,\n",
    "already cleanly organized into images\n",
    "and associated annotation files.\n",
    "\n",
    "But data does not come to us like this.\n",
    "\n",
    "Model inputs are generally collected or measured from the world somehow,\n",
    "and annotations are often collected from humans.\n",
    "\n",
    "Let's now walk through how that's done.\n",
    "\n",
    "We'll use a dataset of text prompts\n",
    "and handwritten responses collected during the 2019 edition of FSDL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFAGLvKtR4IX"
   },
   "source": [
    "## Handling Data with AWS S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3JwClhTHBvT"
   },
   "source": [
    "We begin a few steps after the beginning:\n",
    "data has been collected from humans who were tasked with\n",
    "writing out text prompts by hand on paper forms,\n",
    "and those forms were scanned and digitized.\n",
    "\n",
    "The digitized forms were placed in storage on Amazon Web Services'\n",
    "Simple Storage Service, aka S3,\n",
    "which is a form of\n",
    "[object storage](https://en.wikipedia.org/wiki/Object_storage).\n",
    "\n",
    "Objects are placed into _buckets_.\n",
    "Buckets are, under the hood, totally flat,\n",
    "unlike the tree-structured storage we have in filesystems.\n",
    "Buckets cannot contain buckets, only objects.\n",
    "\n",
    "However, we can organize buckets into folders,\n",
    "which can contain folders,\n",
    "getting back something that looks a bit more like a traditional filesystem,\n",
    "but which is now internet-native.\n",
    "\n",
    "For example, the forms in our dataset all have URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzuNcIEbvIHn"
   },
   "outputs": [],
   "source": [
    "s3_bucket_name = \"fsdl-public-assets\"  # objects are placed into buckets\n",
    "s3_directory_path = \"fsdl_handwriting_20190302\"  # buckets can contain \"folders\" for organization\n",
    "# we combine this information into a base URL format for the data:\n",
    "s3_url = f\"https://{s3_bucket_name}.s3.us-west-2.amazonaws.com/{s3_directory_path}\"\n",
    "s3_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nrag5zsUHi_f"
   },
   "source": [
    "Because this S3 bucket is publicly accessible,\n",
    "the contents can be displayed just using the URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrT3XzkdHnb-"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "idx = 117\n",
    "img_url = f\"{s3_url}/page-{str(idx).zfill(3)}.jpg\"\n",
    "print(img_url)\n",
    "Image(url=img_url, width=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kpoo_N8YHghg"
   },
   "source": [
    "That's nice for basic tasks,\n",
    "like accessing an individual file.\n",
    "For programmatic access to large numbers of files,\n",
    "we'll want an SDK or a CLI.\n",
    "\n",
    "We use\n",
    "[`boto3`](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html),\n",
    "the Python SDK for Amazon Web Services.\n",
    "\n",
    "It is named after the Portuguese term for\n",
    "[river dolphins native to the Amazon river](https://en.wikipedia.org/wiki/Boto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7Mvx6wMirga"
   },
   "outputs": [],
   "source": [
    "import boto3  # boto3: high-level API\n",
    "from botocore import UNSIGNED  # botocore: lower-level API and components\n",
    "from botocore.config import Config\n",
    "\n",
    "\n",
    "# spin up a client for communicating with s3 without authenticating (\"UNSIGNED\" activity)\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-Ur0wAuvIHo"
   },
   "source": [
    "Let's start by just downloading a single file\n",
    "to the local filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLCvaWgfJpi-"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "from text_recognizer.metadata.shared import DATA_DIRNAME\n",
    "\n",
    "\n",
    "FSDL_RAW_DATA_DIRNAME = DATA_DIRNAME / \"raw\" / \"fsdl_handwriting\"\n",
    "FSDL_DL_DATA_DIRNAME = DATA_DIRNAME / \"downloaded\" / \"fsdl_handwriting\"/ \"pages\"\n",
    "\n",
    "!mkdir -p {FSDL_DL_DATA_DIRNAME}\n",
    "\n",
    "s3.download_file(\n",
    "    \"fsdl-public-assets\", \"fsdl_handwriting_20190302/page-001.jpg\", f\"{FSDL_DL_DATA_DIRNAME}/page-001.jpg\")\n",
    "\n",
    "Image(filename=f\"{FSDL_DL_DATA_DIRNAME}/page-001.jpg\", width=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4szA6WPvIHo"
   },
   "source": [
    "To pull down more data,\n",
    "e.g. all 117 forms from this dataset,\n",
    "we'll need to write a helper method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3AkQCxQkkvWu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "s3_resource = boto3.resource('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "\n",
    "def download_s3_folder(bucket_name, s3_folder, local_dir=None):\n",
    "    \"\"\"Download the contents of a folder on S3, recursively.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bucket_name: the name of the s3 bucket\n",
    "    s3_folder: the folder path in the s3 bucket\n",
    "    local_dir: a relative or absolute directory path in the local file system\n",
    "    \"\"\"\n",
    "    # from https://stackoverflow.com/questions/49772151/download-a-folder-from-s3-using-boto3\n",
    "    bucket = s3_resource.Bucket(bucket_name)\n",
    "    for obj in bucket.objects.filter(Prefix=s3_folder):\n",
    "        target = obj.key if local_dir is None \\\n",
    "            else os.path.join(local_dir, os.path.relpath(obj.key, s3_folder))\n",
    "        if not os.path.exists(os.path.dirname(target)):\n",
    "            os.makedirs(os.path.dirname(target))\n",
    "        if obj.key[-1] == '/':\n",
    "            continue\n",
    "        bucket.download_file(obj.key, target)\n",
    "        \n",
    "        \n",
    "download_s3_folder(\"fsdl-public-assets\", \"fsdl_handwriting_20190302\", FSDL_DL_DATA_DIRNAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhrbyDz4k7FK"
   },
   "source": [
    "We can confirm this worked by checking the directory contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yB0nBexmGbw"
   },
   "outputs": [],
   "source": [
    "!find {FSDL_DL_DATA_DIRNAME} | head -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmSNfRunvIHp"
   },
   "source": [
    "For more on using `boto3` with S3,\n",
    "including authentication, uploading, and configuration,\n",
    "we refer the interested reader to the\n",
    "[Real Python tutorial](https://realpython.com/python-boto3-aws-s3/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vl0tfqXuR6Sx"
   },
   "source": [
    "## Annotation with Label Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ct3PogljvIHq"
   },
   "source": [
    "As noted above,\n",
    "these raw forms are not useful for learning the text recognition task.\n",
    "\n",
    "There are no targets for our model to learn to produce and\n",
    "there are no other annotations that can help us transform the data,\n",
    "e.g. pulling out paragraphs or lines.\n",
    "\n",
    "In this as in most cases, these annotations must be added manually.\n",
    "\n",
    "Many programmers and data scientists consider this sort of manual labor\n",
    "to be uninteresting and so ignore it or outsource it entirely.\n",
    "\n",
    "This is a mistake!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PodS_Xlvl2R"
   },
   "source": [
    "### Configuring and connecting to the web server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fld3FylCvIHr"
   },
   "source": [
    "Much like many of the other tools we have used so far\n",
    "(TensorBoard, W&B, Jupyter)\n",
    "Label Studio operates on a client-server model,\n",
    "with clients mostly using a browser.\n",
    "\n",
    "Here, the annotation server tracks things like\n",
    "- user authentication credentials\n",
    "- annotation task definitions\n",
    "- past annotation information\n",
    "- which data still requires annotation\n",
    "\n",
    "The client's browser renders the annotation interface,\n",
    "where users can click and type to annotate the data visually and interactively,\n",
    "with the results saved as structured text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9S2SWUT1vIHr"
   },
   "source": [
    "So we'll be running a labelling webservice.\n",
    "\n",
    "That means that before we can spin Label Studio up,\n",
    "we'll need to solve a few problems.\n",
    "\n",
    "First, we need to configure the administrative user\n",
    "with a username and a password:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZZPWLP6X1AS"
   },
   "outputs": [],
   "source": [
    "username = \"fsdl@localhost\"\n",
    "password = \"pancakes\"\n",
    "\n",
    "%env LABEL_STUDIO_USERNAME={username}\n",
    "%env LABEL_STUDIO_PASSWORD={password}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zpV6puVvIHs"
   },
   "source": [
    "Notice that we are configuring our web service\n",
    "with environment variables\n",
    "(`%env` in Jupyter).\n",
    "\n",
    "This is considered\n",
    "[a good design pattern for applications](https://12factor.net/config)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4jTzGoCvIHs"
   },
   "source": [
    "We'll be running the webservice from this notebook,\n",
    "but we want to be able to connect to it from the public internet.\n",
    "\n",
    "You can set this up yourself if you have control of the network\n",
    "and device you are using and know a bit about\n",
    "firewalls and port-forwarding.\n",
    "\n",
    "But this isn't always the case,\n",
    "and even when it is,\n",
    "often requires platform-specific\n",
    "configuration.\n",
    "\n",
    "The easiest way to set up a basic webservice\n",
    "without worrying about these issues is a tool called\n",
    "[`ngrok`](https://ngrok.io/),\n",
    "which we'll also use when it comes time to serve our application.\n",
    "\n",
    "[Sign up for a free `ngrok` account](https://dashboard.ngrok.com/signup)\n",
    "and then run the cell below\n",
    "to enter your authentication token\n",
    "if you haven't done so already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nr6EFk_suy3d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "from pyngrok import ngrok\n",
    "\n",
    "config_file = ngrok.conf.DEFAULT_NGROK_CONFIG_PATH\n",
    "config_file_exists =  os.path.exists(config_file)\n",
    "config_file_contents = !cat {config_file}\n",
    "\n",
    "auth_token_found = config_file_exists \\\n",
    "    and config_file_contents \\\n",
    "    and \"authtoken\" in config_file_contents[0] \\\n",
    "    and \": exit\" not in config_file_contents  # state if interrupted\n",
    "\n",
    "if not auth_token_found:\n",
    "    print(\"Enter your ngrok auth token, which can be copied from https://dashboard.ngrok.com/auth\")\n",
    "    !ngrok authtoken {getpass.getpass()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZrBZRXtvIHs"
   },
   "source": [
    "`ngrok` creates a tunnel from the local service\n",
    "to the ngrok.io servers\n",
    "and then exposes that service via an ngrok-controlled URL.\n",
    "\n",
    "The cell below creates a tunnel pointing at the local port\n",
    "on which Label Studio will be listening for requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhDcoGI9Ry_W",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "LABEL_STUDIO_PORT = 8081\n",
    "%env LABEL_STUDIO_PORT={LABEL_STUDIO_PORT}\n",
    "\n",
    "https_tunnel = ngrok.connect(LABEL_STUDIO_PORT, bind_tls=True)\n",
    "print(https_tunnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23gsKGAHuy3d"
   },
   "source": [
    "Lastly, we need to install Label Studio,\n",
    "because Label Studio is not included\n",
    "in the development environment\n",
    "for the labs.\n",
    "\n",
    "That's because it's not compatible with many of our other libraries,\n",
    "due to a very strict requirement specification.\n",
    "\n",
    "Rather than expecting to be used as one library among many\n",
    "in a development environment,\n",
    "like the rest of our tools,\n",
    "Label Studio expects to be used more like an application.\n",
    "\n",
    "That means it's generally run on a server or inside of a container\n",
    "that isn't doing anything else.\n",
    "\n",
    "Because of these constraints,\n",
    "we'll briefly install Label Studio here, from inside the notebook,\n",
    "and then clean it up from our environment at the end,\n",
    "by re-running our `make pip-tools` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQO1ewncuy3d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -qqq label-studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTCX7UWSvIHt"
   },
   "source": [
    "Now, we're ready to kick off our webservice by running it (`script bash`)\n",
    "in the `b`ack`g`round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-OolSabuy3e"
   },
   "outputs": [],
   "source": [
    "%%script bash --bg --proc label_studio_proc\n",
    "\n",
    "label-studio start --port=$LABEL_STUDIO_PORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7laZW302jgc"
   },
   "source": [
    "It should take at most 30 seconds to start.\n",
    "\n",
    "Once it has,\n",
    "you can put the URL below into your browser\n",
    "to access the Label Studio server\n",
    "and log in with the credentials below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Py6cwJAE1yI7"
   },
   "outputs": [],
   "source": [
    "print(https_tunnel.public_url)\n",
    "print(\"u:\", username)\n",
    "print(\"p:\", password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_hzktPwvIHu"
   },
   "source": [
    "See the\n",
    "[video walkthrough for this lab](https://fsdl.me/2022-lab-06-video)\n",
    "for a tour of the interface\n",
    "and a demonstration of how to set up data labelling for the first exercise below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYtJrWfnvIHu"
   },
   "source": [
    "### Uploading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7gX8UfrvIHu"
   },
   "source": [
    "Label Studio isn't particularly useful without data to label.\n",
    "\n",
    "The simplest format that Label Studio accepts is a CSV\n",
    "where each row is a different datapoint.\n",
    "\n",
    "The cell below prints the path and first ten lines\n",
    "of a CSV in this format for the FSDL Handwriting dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_3SeV2MHRoM"
   },
   "outputs": [],
   "source": [
    "print(FSDL_RAW_DATA_DIRNAME / \"manifest.csv\")\n",
    "!cat {FSDL_RAW_DATA_DIRNAME}/manifest.csv | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gi6y8Zy8vIHv"
   },
   "source": [
    "In Label Studio,\n",
    "you can upload this file via the \"Import Data\" interface.\n",
    "\n",
    "Note that the interface opens a file dialog box on the machine running the browser,\n",
    "which may not be the same machine executing the notebook where this CSV file is written.\n",
    "\n",
    "In that case, you'll need to download the CSV file to your machine using the file tools\n",
    "built into Jupyter/Colab\n",
    "before you can upload it to Label Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09zvo8xMkNVO"
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMScXTVXkOrk"
   },
   "source": [
    "### 🌟 Label at least five pages of data in Label Studio.\n",
    "\n",
    "Follow the instructions in the video to set up\n",
    "the annotation task and then complete it for at least five pages' worth of data.\n",
    "\n",
    "As you're doing so,\n",
    "pay close attention to the data.\n",
    "\n",
    "Where are there unexpected ambiguities or edge cases?\n",
    "How do you resolve them?\n",
    "\n",
    "In general, you'll want to consider the downstream model behavior\n",
    "you intend to exemplify with the data\n",
    "and the data you expect the model to see in production.\n",
    "\n",
    "Here are three interesting pages,\n",
    "which range from very obvious issues to very subtle ones: #24, #35, #97."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-N27-Lu8NtfG"
   },
   "source": [
    "### 🌟🌟 Hook up S3 directly to Label Studio.\n",
    "\n",
    "Label Studio makes it very straightforward to hook data in cloud storage,\n",
    "like our data, into the labelling server.\n",
    "\n",
    "However, it requires an AWS account, since\n",
    "integrating with cloud storage\n",
    "is typically used with controlled access.\n",
    "\n",
    "If you don't have one already,\n",
    "[create an AWS account](https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/).\n",
    "We won't be using any paid features.\n",
    "\n",
    "Then, follow the guide\n",
    "[here](https://labelstud.io/guide/storage.html#Set-up-connection-in-the-Label-Studio-UI).\n",
    "\n",
    "Because our data is public,\n",
    "you will not need to configure access with IAM, use pre-signed URLs or provide a Session Token.\n",
    "\n",
    "Our region is `us-west-2`.\n",
    "The bucket name and bucket prefix are above,\n",
    "in the section on downloading from S3 with `boto3`.\n",
    "\n",
    "For the filter regex, note that all files end with `.jpg`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzWzIKtZuy3e"
   },
   "source": [
    "# Teardown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RoTvNOsvIHw"
   },
   "source": [
    "As described above,\n",
    "the Label Studio application\n",
    "isn't part of our model development environment,\n",
    "so we need to uninstall it before moving on to future labs.\n",
    "\n",
    "The cell below shuts down Label Studio and,\n",
    "for notebooks running locally,\n",
    "returns the environment to its default state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4460l_Shuy3e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "in_colab = \"google.colab\" in sys.modules\n",
    "done_with_label_studio = True\n",
    "\n",
    "if done_with_label_studio:\n",
    "    !pkill -P {label_studio_proc.pid}\n",
    "    if not in_colab:  # colab environments are ephemeral, no need to clean up\n",
    "        if \"Makefile\" in os.listdir():\n",
    "            !make pip-tools-lint\n",
    "        else:\n",
    "            !cd ../ && make pip-tools"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab06_data.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
