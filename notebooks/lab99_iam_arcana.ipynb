{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3152a044",
   "metadata": {},
   "source": [
    "<img src=\"https://fsdl.me/logo-720-dark-horizontal\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33333208",
   "metadata": {},
   "source": [
    "# Arcane Information about the IAM Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba201d59",
   "metadata": {},
   "source": [
    "This notebook walks through the code for handling the `IAM` dataset\n",
    "that underlies our line- and paragraph-level text recognition datasets.\n",
    "\n",
    "It's intended to write down and make visible the fiddly details of data processing that are otherwise easily lost when code is handed off between engineers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d47af",
   "metadata": {},
   "source": [
    "It runs against the source repo, rather than the labs repo,\n",
    "so we include an environment variable to change the `bootstrap` behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a88524",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env FSDL_REPO=fsdl-text-recognizer-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6548ee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_idx = None\n",
    "\n",
    "if \"bootstrap\" not in locals() or bootstrap.run:\n",
    "    # path management for Python\n",
    "    pythonpath, = !echo $PYTHONPATH\n",
    "    if \".\" not in pythonpath.split(\":\"):\n",
    "        pythonpath = \".:\" + pythonpath\n",
    "        %env PYTHONPATH={pythonpath}\n",
    "        !echo $PYTHONPATH\n",
    "\n",
    "    # get both Colab and local notebooks into the same state\n",
    "    !wget --quiet https://fsdl.me/gist-bootstrap -O bootstrap.py\n",
    "    import bootstrap\n",
    "\n",
    "    # change into the lab directory\n",
    "    bootstrap.change_to_lab_dir(lab_idx=lab_idx)\n",
    "\n",
    "    # allow \"hot-reloading\" of modules\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    # needed for inline plots in some contexts\n",
    "    %matplotlib inline\n",
    "\n",
    "    bootstrap.run = False  # change to True re-run setup\n",
    "    \n",
    "!pwd\n",
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d32bbd6",
   "metadata": {},
   "source": [
    "# Wipe the Slate Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2537c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.metadata.iam import DL_DATA_DIRNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639c3a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_fresh = False\n",
    "\n",
    "if starting_fresh:\n",
    "    !rm -rf {DL_DATA_DIRNAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3438d2e",
   "metadata": {},
   "source": [
    "This class downloads the data --\n",
    "we'll talk more about it later,\n",
    "but we want to have the data present for the first part of the discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18900eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.data.iam import IAM\n",
    "\n",
    "iam = IAM()\n",
    "iam.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499c23a6",
   "metadata": {},
   "source": [
    "# Reviewing the Stucture of the Data on Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a332f359",
   "metadata": {},
   "source": [
    "\n",
    "The `IAM` dataset is downloaded as zip file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c44266",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_dir = DL_DATA_DIRNAME\n",
    "!ls {iam_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8463c2d1",
   "metadata": {},
   "source": [
    "Inside that zip file are the following files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536924f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iamdb = iam_dir / \"iamdb\"\n",
    "\n",
    "!du -h {iamdb}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9866dc52",
   "metadata": {},
   "source": [
    "## Where are the \"inputs\" and \"targets\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64240b05",
   "metadata": {},
   "source": [
    "There are >3000 files, almost all of which are `.xml` or `.jpg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea605de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find {iamdb} | grep \"\\.jpg$\\|\\.xml$\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53b475c",
   "metadata": {},
   "source": [
    "And they are equal in number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514bfd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find {iamdb}/xml | grep \"\\.xml$\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73309c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find {iamdb}/forms | grep \"\\.jpg$\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dbaff6",
   "metadata": {},
   "source": [
    "Where there are many small files in equal number, there are inputs and targets.\n",
    "\n",
    "And indeed, an individual \"datapoint\" in `IAM` is a \"form\", because the humans whose hands wrote the data were writing on \"forms\", as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d5e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import text_recognizer.util as util\n",
    "\n",
    "\n",
    "file, = !find {iamdb}/forms | grep \".jpg$\" | head -n 1\n",
    "\n",
    "print(file)\n",
    "util.read_image_pil(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e9e384",
   "metadata": {},
   "source": [
    "And the `xml` files indeed contain the targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6add5c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file, = !find {iamdb}/xml | grep \"\\.xml$\" | head -n 1\n",
    "\n",
    "!cat {file} | grep -A 100 \"handwritten-part\" | grep \"<word\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d3389c",
   "metadata": {},
   "source": [
    "But they also contain the metadata required to convert images of entire forms into more useful images, e.g. of lines or paragraphs of handwritten text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b063e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file, = !find {iamdb}/xml | grep \"\\.xml$\" | head -n 1\n",
    "\n",
    "!cat {file} | grep -A 25 \"handwritten-part\" | grep -A 5 \"<word\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd51b664",
   "metadata": {},
   "source": [
    "The `ascii` folder has metadata in `.txt` files in the ASCII format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745a594",
   "metadata": {},
   "source": [
    "There's a handful of other files full of metadata -- e.g. the training, validation, and test splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c21f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find {iamdb} | grep \"\\\\.txt$\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a831c393",
   "metadata": {},
   "source": [
    "The `ascii` folder has metadata in `.txt` files in the ASCII format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa7b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh {iamdb}/ascii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361023ff",
   "metadata": {},
   "source": [
    "# `IAM`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57a11db",
   "metadata": {},
   "source": [
    "The `data.iam` module and `IAM` class\n",
    "have a bunch of useful utilities for managing this data,\n",
    "plus a `prepare_data` method that just downloads and unzips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e04663",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = IAM()\n",
    "iam.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003f8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feb1f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc5331",
   "metadata": {},
   "source": [
    "## `IAMLines`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844b92d5",
   "metadata": {},
   "source": [
    "We start from the raw forms and need to get to lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9359e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import text_recognizer.util as util\n",
    "\n",
    "fn = iam.form_filenames[0]\n",
    "\n",
    "print(fn)\n",
    "img = util.read_image_pil(fn)\n",
    "print(img.size)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9255704",
   "metadata": {},
   "source": [
    "There's a high-level method that returns the lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabd9f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.data.iam_lines import generate_line_crops_and_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56257306",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops, labels = generate_line_crops_and_labels(iam, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(crops[0]), type(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdcba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels[0])\n",
    "print(crops[0].size)\n",
    "crops[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b7d5f9",
   "metadata": {},
   "source": [
    "But the details matter here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461cc9b7",
   "metadata": {},
   "source": [
    "So let's look at the code, first all at once, then step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766feba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_line_crops_and_labels??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05e0657",
   "metadata": {},
   "source": [
    "And we'll apply the procedure to this image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81b7c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = util.read_image_pil(fn)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa9fef9",
   "metadata": {},
   "source": [
    "We iterate over the `ids` from the dataset `split` of interest, here `test`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b903b55",
   "metadata": {},
   "source": [
    "We first pull the labels, using the form ID,\n",
    "which we can pull here easily\n",
    "because it's also the filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd51089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fn.stem)\n",
    "print(\"\", *iam.line_strings_by_id[fn.stem], sep=\"\\n\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20994794",
   "metadata": {},
   "source": [
    "We operate on these files using `PIL` utilities -- inside of `iam.load_image`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fe67ea",
   "metadata": {},
   "source": [
    "First, from RGB to `grayscale`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32469c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08899eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_g = ImageOps.grayscale(img)\n",
    "img_g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbbc4d0",
   "metadata": {},
   "source": [
    "then -- importantly! -- we invert it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257434d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmi = ImageOps.invert(img_g)\n",
    "gmi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a397272e",
   "metadata": {},
   "source": [
    "We then pull out the `coord`inate`s` of the line crops using the `line_regions_by_id` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa18594",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam.line_regions_by_id[fn.stem]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06df28c9",
   "metadata": {},
   "source": [
    "Quick sanity check with direct array manipulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9968e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "idx = 0\n",
    "line_coords = iam.line_regions_by_id[fn.stem][idx]\n",
    "im_arr = np.array(gmi)\n",
    "im_arr[line_coords[\"y1\"]:line_coords[\"y2\"], line_coords[\"x1\"]:line_coords[\"x2\"]] += 100\n",
    "\n",
    "plt.matshow(im_arr, cmap=\"Greys_r\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e089da",
   "metadata": {},
   "source": [
    "And we pull them out with a `crop` operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = gmi.crop(line_coords[point] for point in [\"x1\", \"y1\", \"x2\", \"y2\"])\n",
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feffd1d9",
   "metadata": {},
   "source": [
    "And resize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf40e7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_line = line.resize((line.width // 2, line.height // 2))\n",
    "print(smaller_line.size)\n",
    "smaller_line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3165d9",
   "metadata": {},
   "source": [
    "# `IAMParagraphs`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dbf6b7",
   "metadata": {},
   "source": [
    "We again use a high-level method to get the `crops_and_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6983575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.data.iam_paragraphs import get_paragraph_crops_and_labels\n",
    "\n",
    "p_crops, p_labels = get_paragraph_crops_and_labels(iam, split=\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a880a214",
   "metadata": {},
   "source": [
    "But now we have `dict`s as outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3095e00b",
   "metadata": {},
   "source": [
    "Let's get the data for the form we were just working with. Note that we had to pick a different split above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3076c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_crop, p_label = p_crops[fn.stem], p_labels[fn.stem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5cab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90edbd5",
   "metadata": {},
   "source": [
    "We read the image,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cae83d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = util.read_image_pil(fn)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00891324",
   "metadata": {},
   "source": [
    "Then we grayscale it and invert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ca92ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_g = ImageOps.grayscale(img)\n",
    "gmi = ImageOps.invert(img_g)\n",
    "gmi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b401a60",
   "metadata": {},
   "source": [
    "We need to go from \"line regions\" to \"paragraph regions\", which means \"concatenating\" the lines -- by joining with min/max."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a672094",
   "metadata": {},
   "source": [
    "That data is inside `iam.paragraph_region_by_id`, which is computed but shows up as just a `dict`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b475a2d8",
   "metadata": {},
   "source": [
    "Quick sanity check with direct array manipulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea696a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "idx = 0\n",
    "para_coords = iam.paragraph_region_by_id[fn.stem]\n",
    "im_arr = np.array(gmi)\n",
    "im_arr[para_coords[\"y1\"]:para_coords[\"y2\"], para_coords[\"x1\"]:para_coords[\"x2\"]] += 100\n",
    "\n",
    "plt.matshow(im_arr, cmap=\"Greys_r\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f40199",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_text = iam.paragraph_string_by_id[fn.stem]\n",
    "print(fn.stem)\n",
    "print(p_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51429a68",
   "metadata": {},
   "source": [
    "and again, we crop and scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a512bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_crop = gmi.crop(para_coords.values())\n",
    "p_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cecee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_p_crop = p_crop.resize((p_crop.size[0] // 2, p_crop.size[1] // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ceb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_p_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4422a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_p_crop.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6175437",
   "metadata": {},
   "source": [
    "This size information percolates into the definitions of models --\n",
    "we use it to set the target input shapes,\n",
    "even though the models can handle different sizes.\n",
    "\n",
    "So it's important to make sure the `metadata` files for\n",
    "`iam`, `iam_lines`, and `iam_paragraphs` are changed together\n",
    "and that the values are compatible with the assumptions of the relevant models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b7ab85",
   "metadata": {},
   "source": [
    "# `IAMSyntheticParagraphs`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db84b799",
   "metadata": {},
   "source": [
    "We use data synthesis to bootstrap our data -- better models on a budget."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2bdb1",
   "metadata": {},
   "source": [
    "## High-Level Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc50f35f",
   "metadata": {},
   "source": [
    "In the `prepare_data` method of this class,\n",
    "we again pull out _line_ crops and save them to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d5ab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_line_crops, s_line_labels = generate_line_crops_and_labels(iam, \"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ceb658",
   "metadata": {},
   "source": [
    "Then, we generate the synthetic _paragraph_ crops and labels during `setup`,\n",
    "using `generate_synthetic_paragraphs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.data.iam_synthetic_paragraphs import (\n",
    "    generate_synthetic_paragraphs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb1e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, para_labels = generate_synthetic_paragraphs(s_line_crops, s_line_labels)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (crop, label) in enumerate(zip(X, para_labels)):\n",
    "    if \"\\n\" in label:\n",
    "        first_paragraph, first_label = crop, label\n",
    "        break\n",
    "        \n",
    "print(str(idx) + \":\\n\", label)\n",
    "first_paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3884e4fe",
   "metadata": {},
   "source": [
    "## Arcane Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d16cf9",
   "metadata": {},
   "source": [
    "We want to build fake paragraphs (with labels!) out of real lines with labels.\n",
    "\n",
    "So first let's make that possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edffc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.data import paragraph_synthesis as psyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "psyn.build_paragraph_from_indices??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712c3ca5",
   "metadata": {},
   "source": [
    "The meat of this function is `join_line_crops_to_from_paragraph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03dfd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "psyn.join_line_crops_to_form_paragraph??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6092518d",
   "metadata": {},
   "source": [
    "And if we grab the first few crops and labels, we can generate a new labeled paragraph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f869d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_synth_crop, sample_synth_label = psyn.build_paragraph_from_indices(s_line_crops[:3], s_line_labels[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26593b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_synth_label)\n",
    "sample_synth_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b9668b",
   "metadata": {},
   "source": [
    "But this is just a snippet of an existing paragraph!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86afa104",
   "metadata": {},
   "source": [
    "We need to be able to create _random combinations_ of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042dab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_synth_crop, sample_synth_label = psyn.build_paragraph_from_indices(\n",
    "    random.choices(s_line_crops, k=3), random.choices(s_line_labels, k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f210c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_synth_label)\n",
    "sample_synth_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7357ef37",
   "metadata": {},
   "source": [
    "That's more like it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10493414",
   "metadata": {},
   "source": [
    "From here, we want to get a method that works on a whole dataset at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "psyn._build_paragraphs_from_indices??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c062f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(s_line_crops)))\n",
    "shuffled_indices = indices.copy()\n",
    "random.shuffle(shuffled_indices)\n",
    "\n",
    "cur_idx, shorter_paragraph_indices = 0, []\n",
    "while cur_idx < len(shuffled_indices) // 5:\n",
    "    shorter_paragraph_indices.append(shuffled_indices[cur_idx : cur_idx + 3])\n",
    "    cur_idx += 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_para_crops, short_para_labels = psyn._build_paragraphs_from_indices(\n",
    "    shorter_paragraph_indices, s_line_crops, s_line_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4c5766",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(short_para_crops))  # now we've got more paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db076cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = random.choice(range(len(short_para_crops)))\n",
    "\n",
    "print(short_para_labels[idx])\n",
    "short_para_crops[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060d9966",
   "metadata": {},
   "source": [
    "But we want varying lengths of paragraphs.\n",
    "\n",
    "We _could_ have just done that directly, by picking some distribution over lengths,\n",
    "but instead we've got a slightly baroque mechanism for taking the existing lines\n",
    "and partitioning them into new paragraphs based on this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c0ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "psyn.generate_random_partition??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27071dc9",
   "metadata": {},
   "source": [
    "This allows us to have multiple instances of each line from the real data in the synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4254d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_paragraph_indices = psyn.generate_random_partition(\n",
    "    indices, min_size=2, max_size=4)\n",
    "long_paragraph_indices = psyn.generate_random_partition(\n",
    "    indices, min_size=5, max_size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f78b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_para_crops, long_para_labels = psyn._build_paragraphs_from_indices(long_paragraph_indices, s_line_crops, s_line_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e36db",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.choice(range(len(long_para_crops)))\n",
    "\n",
    "print(long_para_labels[idx])\n",
    "long_para_crops[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5264ba",
   "metadata": {},
   "source": [
    "We wrap all this up in a big ol' grandaddy function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d400fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "psyn.generate_synthetic_paragraphs??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca3369",
   "metadata": {},
   "source": [
    "Which provides our abstracted high-level interface for paragraph generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
