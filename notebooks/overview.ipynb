{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yQQTA9IGDt8"
      },
      "source": [
        "<img src=\"https://fsdl.me/logo-720-dark-horizontal\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX9n-Zed8G_T"
      },
      "source": [
        "# Lab 00: The ðŸ¥ž Full Stack ðŸ¥ž of the Text Recognizer Application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OggjLhU3f9gk"
      },
      "source": [
        "In the course of these labs,\n",
        "you will build an optical character recognition (OCR) application\n",
        "that is powered by a neural network:\n",
        "the \"FSDL Text Recognizer\".\n",
        "\n",
        "We use this application to\n",
        "- demonstrate general principles for engineering an ML-powered application,\n",
        "- provide a \"worked example\" that includes all of the juicy details, and\n",
        "- introduce you to tools, libraries, and practices that we consider best-in-class or best for independent ML engineers working across the full stack.\n",
        "\n",
        "You can try it out inside this notebook below,\n",
        "or you can simply navigate to the `app_url` in your browser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9xKjSYie6ck"
      },
      "outputs": [],
      "source": [
        "from IPython.display import IFrame\n",
        "\n",
        "app_url = \"https://fsdl-text-recognizer.ngrok.io/\"\n",
        "\n",
        "IFrame(app_url, width=1024, height=896)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaDkEosIjcl6"
      },
      "source": [
        "## Frontend and Backend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDxvNgFHgM_J"
      },
      "source": [
        "What you see above is the \"frontend\",\n",
        "the user-facing component, of the application.\n",
        "\n",
        "Frontend web development is typically done using\n",
        "Javascript as the programming language.\n",
        "Most ML is done in Python (see below),\n",
        "so we will instead build our frontend using\n",
        "the Python library [**Gradio**](https://gradio.app/).\n",
        "\n",
        "> <small>Another excellent choice for pure Python web development might be\n",
        "[Streamlit](https://streamlit.io/)\n",
        "or even, in the near future, tools built around\n",
        "[PyScript](https://pyscript.net/).</small>\n",
        "\n",
        "Notice the option to \"flag\" the model's outputs.\n",
        "This user feedback will be sent to [**Gantry**](https://gantry.io/),\n",
        "where we can monitor model performance,\n",
        "generate alerts,\n",
        "and do exploratory data analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywyH6kW5uUjH"
      },
      "source": [
        "\n",
        "The model that reads the image to produce the text\n",
        "is not running\n",
        "in the same place as the frontend.\n",
        "The model is the \"backend\" of our application.\n",
        "We separate the two via a JSON API.\n",
        "The model is deployed\n",
        "[serverlessly](https://serverless-stack.com/chapters/what-is-serverless.html)\n",
        "to Amazon Web Services using\n",
        "[**AWS Lambda**](https://aws.amazon.com/lambda/),\n",
        "which runs a\n",
        "[**Docker**](https://docker-curriculum.com/)\n",
        "container that wraps up our model.\n",
        "\n",
        "> <small> Docker is the tool of choice for virtualization/containerization. As containerized applications become more complex,\n",
        "[container orchestration](https://www.vmware.com/topics/glossary/content/container-management.html)\n",
        "becomes important. The premier tool for orchestrating\n",
        "Docker containers is\n",
        "[kubernetes](https://kubernetes.io/), aka k8s.\n",
        "Non-experts on cloud infrastructure will want to use their providers' managed service for k8s, e.g.\n",
        "[AWS EKS](https://aws.amazon.com/eks/)\n",
        "or [Google Kubernetes Engine](https://cloud.google.com/kubernetes-engine).</small>\n",
        "\n",
        "The container image lives inside the\n",
        "[Elastic Container Registry](https://aws.amazon.com/ecr/),\n",
        "a sort of \"GitHub for Docker\" on AWS.\n",
        "The choice to go serverless makes it effortless to scale up our model\n",
        "across a number of orders of magnitude\n",
        "and the choice to containerize reduces friction and error\n",
        "when moving our model from development to production.\n",
        "\n",
        "> <small> This could equally as well be done on another cloud,\n",
        "like [Google Cloud Platform](https://cloud.google.com/)\n",
        "or [Microsoft Azure](https://azure.microsoft.com/en-us/),\n",
        "which offer serverless deployment via\n",
        "[Google Cloud Functions](https://cloud.google.com/serverless)\n",
        "and [Azure Functions](https://azure.microsoft.com/en-us/solutions/serverless),\n",
        "respectively. </small>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The backend operates completely independently of the frontend,\n",
        "which means it can be used in multiple contexts.\n",
        "\n",
        "Run the cell below to send a query directly to the model on the backend."
      ],
      "metadata": {
        "id": "3XBHox87IJ8i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76HwEP2Vzz3F"
      },
      "outputs": [],
      "source": [
        "import json  # JavaScript Object Notation is the lingua franca of the web\n",
        "\n",
        "from IPython.display import Image\n",
        "import requests  # requests is the preferred library for web requests in Python\n",
        "\n",
        "lambda_url = \"https://3akxma777p53w57mmdika3sflu0fvazm.lambda-url.us-west-1.on.aws/\"\n",
        "image_url = \"https://fsdl-public-assets.s3-us-west-2.amazonaws.com/paragraphs/a01-077.png\"\n",
        "\n",
        "headers = {\"Content-type\": \"application/json\"}  # headers ensure our request is handled correctly\n",
        "payload = json.dumps({\"image_url\": image_url})  # the request content is a string representation of JSON data\n",
        "\n",
        "if \"pred\" not in locals():  # a poor man's cache: if we've defined the variable pred, skip the request\n",
        "  response = requests.post(  # we POST the image to the URL, expecting a prediction as a response\n",
        "      lambda_url, data=payload, headers=headers)\n",
        "  pred = response.json()[\"pred\"]  # the response is also json\n",
        "\n",
        "print(pred)\n",
        "\n",
        "Image(url=image_url, width=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csthw0QlgeSy"
      },
      "source": [
        "## Application Diagram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baYhDRKkggNk"
      },
      "source": [
        "We're only halfway through describing how the Text Recognizer works\n",
        "and it's already getting hard to hold the whole thing in-memory.\n",
        "\n",
        "Run the cell below to show a diagram that incorporates the entire\n",
        "process for creating and running the Text Recognizer,\n",
        "from training to feedback collection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsOa6gQ0YhX4"
      },
      "outputs": [],
      "source": [
        "diagram_url = \"https://miro.com/app/live-embed/uXjVOrOHcOg=/?moveToViewport=-1210,-1439,2575,1999\"\n",
        "\n",
        "IFrame(diagram_url, width=1024, height=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiQgHY6Th67H"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib6ijsumjjlm"
      },
      "source": [
        "Let's start back at the beginning -- developing a model.\n",
        "We'll then make our way back to where we left off above, the handoff\n",
        "from model development/training\n",
        "to the actual application.\n",
        "\n",
        "We begin by training a neural network\n",
        "(a [ResNet](https://pytorch.org/hub/pytorch_vision_resnet/)\n",
        "encoder to process the images and \n",
        "a [Transformer](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html)\n",
        "decoder to produce the output text).\n",
        "\n",
        "Neural networks operate by applying\n",
        "sequences of large matrix multiplications\n",
        "and other array operations.\n",
        "These operations are much faster on GPUs than on CPUs\n",
        "and are relatively easy to parallelize\n",
        "across GPUs.\n",
        "This is especially true during training,\n",
        "where many inputs are processed in parallel,\n",
        "or \"batched\" together.\n",
        "\n",
        "Purchasing GPUs and properly setting up\n",
        "a multi-GPU machine is challenging\n",
        "and has high up-front costs.\n",
        "So we run our training via a cloud provider,\n",
        "specifically\n",
        "[**Lambda Labs GPU Cloud**](https://lambdalabs.com/service/gpu-cloud).\n",
        "\n",
        "> <small> Other cloud providers offer GPU-accelerated compute\n",
        "but Lambda Labs offers it at the lowest prices,\n",
        "as of August 2022.\n",
        "Larger organizations may benefit from the extra features\n",
        "that integration with larger cloud providers,\n",
        "like AWS or GCP, can provide (e.g. unified authorization\n",
        "and control planes).\n",
        "Because independent, full-stack developers\n",
        "are often very price-sensitive, we recommend Lambda Labs --\n",
        "even more, we recommend checking current and historical instance prices.\n",
        "</small>\n",
        "\n",
        "For smaller units of work, like debugging and quick experiments,\n",
        "we can use\n",
        "[Google Colaboratory](https://research.google.com/colaboratory/),\n",
        "which provides limited access to free GPU (and TPU)\n",
        "compute in an ephemeral environment.\n",
        "\n",
        "> <small> For small-to-medium-sized deep learning tasks,\n",
        "Colab Pro (\\$10/mo.) and Colab Pro+ (\\$50/mo.)\n",
        "can be competitive with the larger cloud providers.\n",
        "</small>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUS001EIv3H7"
      },
      "source": [
        "If you're running this notebook on a machine with a GPU,\n",
        "e.g. on Colab, running the cell below\n",
        "will show some basic information on the GPU's state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyYVgQmlv091"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-C6iWKAsZI3"
      },
      "source": [
        "Because the heavy work is done on the GPU,\n",
        "using lower-level libraries,\n",
        "we don't need to write the majority of our model development code\n",
        "in a performant language like C/C++ or Rust.\n",
        "\n",
        "We can instead write in a more comfortable, but slower language:\n",
        "it doesn't make sense to drive an F1 car to the airport\n",
        "for an international flight.\n",
        "\n",
        "The language of choice for deep learning is\n",
        "[**Python**](https://www.python.org/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQALjrGVwFeG"
      },
      "outputs": [],
      "source": [
        "import this  # The Zen of Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uqfsWUQwEyl"
      },
      "source": [
        "We don't want to write our Python library for GPU acceleration from scratch,\n",
        "especially because we also need automatic differentiation --\n",
        "the ability to take derivatives of our neural networks.\n",
        "The Python/C++ library\n",
        "[PyTorch](https://pytorch.org/)\n",
        "offers GPU-accelerated array math with automatic differentiation,\n",
        "plus special neural network primitives and architectures.\n",
        "\n",
        "> <small> There are two major alternatives to PyTorch\n",
        "for providing accelerated, differentiable array math,\n",
        "both from Google: early mover\n",
        "[TensorFlow](https://www.tensorflow.org/resources/learn-ml)\n",
        "and new(ish)comer\n",
        "[JAX](https://github.com/google/jax).\n",
        "The former is more common in certain larger, older enterprise settings\n",
        "and the latter is more common in certain bleeding-edge research settings.\n",
        "We choose PyTorch to split the difference,\n",
        "but can confidently recommend all three.\n",
        "</small>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcvCJ6b1wVRl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # run on GPU if available\n",
        "\n",
        "# create an array/tensor and track its gradients during calculations\n",
        "a = torch.tensor([1.], requires_grad=True) \\\n",
        "  .to(device)  # store the array data on GPU (if available)\n",
        "b = torch.tensor([2.]).to(device)\n",
        "\n",
        "# calculate new values, building up a \"compute graph\"\n",
        "c = a * b + a\n",
        "\n",
        "# compute gradient of c with respect to a by \"tracing the graph backwards\"\n",
        "g, = torch.autograd.grad(outputs=c, inputs=a)\n",
        "\n",
        "g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zjQyN4HwUS0"
      },
      "source": [
        "\n",
        "PyTorch provides a number of features required for creating\n",
        "deep neural networks,\n",
        "but it doesn't include a high-level framework\n",
        "for training or any of a number of related engineering tasks,\n",
        "like metric calculation or model checkpointing.\n",
        "\n",
        "We use the\n",
        "[PyTorch Lightning](https://pytorch-lightning.readthedocs.io/en/stable/)\n",
        "library as our high-level training engineering framework.\n",
        "\n",
        "> <small> PyTorch Lightning is the framework of choice\n",
        "for generic deep learning in PyTorch,\n",
        "but in natural language processing,\n",
        "many people instead choose libraries from\n",
        "[Hugging Face](https://hugginface.co/).\n",
        "[Keras](https://keras.io/)\n",
        "is the framework of choice for TensorFlow.\n",
        "In some ways,\n",
        "[Flax](https://github.com/google/flax)\n",
        "is the same for JAX;\n",
        "in others, there is not as of July 2022 a high-level\n",
        "training framework in JAX.</small>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehvGUApGpnrV"
      },
      "outputs": [],
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "\n",
        "lit_video_id = \"QHww1JH7IDU\"\n",
        "YouTubeVideo(lit_video_id, modestbranding=True, rel=False, width=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gu9b4Ux1U-k"
      },
      "source": [
        "## Experiment and Artifact Tracking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWhTbHq3sfON"
      },
      "source": [
        "ML models are challenging to debug:\n",
        "their inputs and outputs are often easy for humans to interpret\n",
        "but hard for traditional software programs to understand.\n",
        "\n",
        "They are also challenging to design:\n",
        "there are a number of knobs to twiddle and constants to set,\n",
        "like a finicky bunch of compiler flags.\n",
        "These are known as \"hyperparameters\".\n",
        "\n",
        "So building an ML model often looks a bit less like engineering\n",
        "and a bit more like experimentation.\n",
        "These experiments need to be tracked,\n",
        "as do large binary files,\n",
        "or artifacts,\n",
        "that are produced during those experiments\n",
        "-- like model weights.\n",
        "\n",
        "We choose\n",
        "[Weights & Biases](http://docs.wandb.ai)\n",
        "as our experiment and artifact tracking platform.\n",
        "\n",
        "> <small> [MLFlow](https://github.com/mlflow/mlflow)\n",
        "is an open-source library that provides similar\n",
        "features to W&B, but the experiment and artifact\n",
        "tracking server must be self-hosted,\n",
        "which can be burdensome for the already beleaguered\n",
        "full-stack ML developer.\n",
        "Basic experiment tracking can also be done\n",
        "using [Tensorboard](https://www.tensorflow.org/tensorboard),\n",
        "and shared using [tensorboard.dev](https://tensorboard.dev/),\n",
        "but Tensorboard does not provide artifact tracking.\n",
        "Artifact tracking and versioning can be done using\n",
        "[Git LFS](https://git-lfs.github.com/),\n",
        "but storage and distribution via GitHub can be expensive\n",
        "and it does not provide experiment tracking.\n",
        "[Hugging Face](https://huggingface.co/) runs an alternative\n",
        "git server, Hugging Face Spaces,\n",
        "that can display Tensorboard experiments and\n",
        "mandates Git LFS for large files (where large means >10MB).\n",
        "</small>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL1uL-SewukM"
      },
      "source": [
        "The resulting experiment logs can be made very rich\n",
        "and are invaluable for debugging\n",
        "(e.g. tracking bugs through the git history)\n",
        "and communicating results inside and across teams.\n",
        "\n",
        "Run the cell below to display the logs from an experiment\n",
        "that was run while designing and debugging the Text Recognizer model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw4LUYkgwvb0"
      },
      "outputs": [],
      "source": [
        "experiment_url = \"https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/runs/lfjjnxw8\"\n",
        "\n",
        "IFrame(experiment_url, width=1024, height=768)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5WHO_CTwrgf"
      },
      "source": [
        "Logged _data_ is inert.\n",
        "It becomes usable, actionable _information_\n",
        "when it is given context and form.\n",
        "\n",
        "Run the cell below to take a look at a dashboard,\n",
        "built inside W&B,\n",
        "reporting the results of a training run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0V-qbh8uWwb"
      },
      "outputs": [],
      "source": [
        "dashboard_url= \"https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/reports/Training-Run-2022-06-02--VmlldzoyMTAyOTkw\"\n",
        "\n",
        "IFrame(dashboard_url, width=1024, height=768)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3I60PY61IXH"
      },
      "source": [
        "## The Handoff to Production"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsT1P1UG1hXW"
      },
      "source": [
        "PyTorch Lightning produces large artifacts called \"checkpoints\"\n",
        "that can be used to restart model training when it stops or is interrupted\n",
        "(which allows the use of much cheaper\n",
        "[\"preemptible\" cloud instances](https://www.determined.ai/blog/scale-your-model-development-on-a-budget)).\n",
        "\n",
        "We store these artifacts on Weights & Biases.\n",
        "\n",
        "When they are ready to be deployed to production,\n",
        "we compile these model checkpoints down to a dialect of Torch called\n",
        "[torchscript](https://pytorch.org/docs/stable/jit.html)\n",
        "that is more portable:\n",
        "it drops the training engineering code\n",
        "and produces an artifact that is executable in C++ or in Python.\n",
        "We stick with a Python environment for simplicity.\n",
        "\n",
        "> <small> TensorFlow has similar facilities\n",
        "for delivering models, including\n",
        "[tensorflow.js](https://www.tensorflow.org/js)\n",
        "and [TensorFlow Extended (TFX)](https://www.tensorflow.org/tfx).\n",
        "There are also a number of alternative portable runtime environments\n",
        "for ML models, including\n",
        "[ONNX RT](https://onnx.ai/).</small>\n",
        "\n",
        "These deployable models are also stored on Weights & Biases,\n",
        "which connects them to rich metadata,\n",
        "including the experiments and training runs\n",
        "that produced the checkpoints from which they were derived.\n",
        "\n",
        "Run the cell below to review the metadata for a deployable\n",
        "version of the Text Recognizer model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AB8OYJ423Qvy"
      },
      "outputs": [],
      "source": [
        "artifact_url = \"https://wandb.ai/cfrye59/fsdl-text-recognizer-2021-training/artifacts/prod-ready/paragraph-text-recognizer/v8\"\n",
        "\n",
        "IFrame(artifact_url, width=1024, height=768)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O6VGIqM3ugW"
      },
      "source": [
        "We can pull this file down,\n",
        "package it into a Docker container\n",
        "via a small Python script,\n",
        "and ship it off to a container registry, like AWS ECR or Docker Hub, so that\n",
        "it can be used to provide the backend to our application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS-1UA1s1hsl"
      },
      "source": [
        "## Application Diagram, Redux"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqr39GhA313z"
      },
      "source": [
        "Now that we have made it through the\n",
        "ðŸ¥ž full stack ðŸ¥ž of the Text Recognizer application,\n",
        "let's take a look at the application diagram again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SH1acJ8f1kpP"
      },
      "outputs": [],
      "source": [
        "IFrame(diagram_url, width=1024, height=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Over the remainder of the labs,\n",
        "we will put all of these pieces together,\n",
        "learning more about the problems they solve,\n",
        "the tradeoffs they make,\n",
        "and how they are best used."
      ],
      "metadata": {
        "id": "j_Yy4d3Dpi3o"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Lab 00 - Overview.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.13 ('fsdl-text-recognizer-2022')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0f056848cf5d2396a4970b625f23716aa539c2ff5334414c1b5d98d7daae66f6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}