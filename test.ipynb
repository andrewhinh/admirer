{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import IPython.display\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd \n",
    "from pyngrok import ngrok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import boto3  # boto3: high-level API\n",
    "from botocore import UNSIGNED  # botocore: lower-level API and components\n",
    "from botocore.config import Config\n",
    "from question_answer.metadata.shared import DATA_DIRNAME, DOWNLOADED_DATA_DIRNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great Expectations + ZenML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install great_expectations s3 dash -y\n",
    "\n",
    "!zenml artifact-store register s3_store \\\n",
    "    --flavor=s3 \\\n",
    "    --path=s3://admirer-pica-zenml-greatexpectations\n",
    "\n",
    "!zenml data-validator register great_expectations \\\n",
    "    --flavor=great_expectations\n",
    "\n",
    "!zenml stack register admirer-pica_stack \\\n",
    "    -o default \\\n",
    "    -a s3_store \\\n",
    "    -dv great_expectations \\\n",
    "    --set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.checkpoint.types.checkpoint_result import (  # type: ignore[import]\n",
    "    CheckpointResult,\n",
    ")\n",
    "\n",
    "from zenml.integrations.constants import GREAT_EXPECTATIONS, SKLEARN\n",
    "from zenml.integrations.great_expectations.steps import (\n",
    "    GreatExpectationsProfilerParameters,\n",
    "    GreatExpectationsProfilerStep,\n",
    "    GreatExpectationsValidatorParameters,\n",
    "    GreatExpectationsValidatorStep,\n",
    ")\n",
    "from zenml.integrations.great_expectations.visualizers import (\n",
    "    GreatExpectationsVisualizer,\n",
    ")\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import BaseParameters, Output, step\n",
    "\n",
    "\n",
    "from zenml.steps import (\n",
    "    STEP_ENVIRONMENT_NAME,\n",
    "    StepEnvironment,\n",
    ")\n",
    "from zenml.environment import Environment\n",
    "from typing import cast\n",
    "\n",
    "\n",
    "from zenml.config import DockerSettings\n",
    "\n",
    "\n",
    "from zenml.post_execution import get_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app_gradio import app\n",
    "from question_answer.answer import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 training/wab.py --fetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket_name = \"admirer-pica\"  # objects are placed into buckets\n",
    "s3_directory_path = \"images\"  # buckets can contain \"folders\" for organization\n",
    "# we combine this information into a base URL format for the data:\n",
    "s3_url = f\"https://{s3_bucket_name}.s3.us-west-1.amazonaws.com/{s3_directory_path}\"\n",
    "s3_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_idx = 1\n",
    "image_idx = 1\n",
    "img_url = f\"{s3_url}/{str(person_idx).zfill(3)}_{str(image_idx).zfill(2)}.png\"\n",
    "print(img_url)\n",
    "# Image(url=img_url, width=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADMIRER_RAW_DATA_DIRNAME = DATA_DIRNAME / \"raw\" / s3_bucket_name\n",
    "ADMIRER_DL_DATA_DIRNAME = DOWNLOADED_DATA_DIRNAME / s3_bucket_name / s3_directory_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spin up a client for communicating with s3 without authenticating (\"UNSIGNED\" activity)\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "!mkdir -p {ADMIRER_DL_DATA_DIRNAME}\n",
    "\n",
    "s3.download_file(\n",
    "    s3_bucket_name, s3_directory_path + \"/001_01.png\", f\"{ADMIRER_DL_DATA_DIRNAME}/001_01.png\")\n",
    "\n",
    "# Image(filename=f\"{ADMIRER_DL_DATA_DIRNAME}/001_01.png\", width=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = boto3.resource('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "\n",
    "def download_s3_folder(bucket_name, s3_folder, local_dir=None):\n",
    "    \"\"\"Download the contents of a folder on S3, recursively.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bucket_name: the name of the s3 bucket\n",
    "    s3_folder: the folder path in the s3 bucket\n",
    "    local_dir: a relative or absolute directory path in the local file system\n",
    "    \"\"\"\n",
    "    # from https://stackoverflow.com/questions/49772151/download-a-folder-from-s3-using-boto3\n",
    "    bucket = s3_resource.Bucket(bucket_name)\n",
    "    for obj in bucket.objects.filter(Prefix=s3_folder):\n",
    "        target = obj.key if local_dir is None \\\n",
    "            else os.path.join(local_dir, os.path.relpath(obj.key, s3_folder))\n",
    "        if not os.path.exists(os.path.dirname(target)):\n",
    "            os.makedirs(os.path.dirname(target))\n",
    "        if obj.key[-1] == '/':\n",
    "            continue\n",
    "        bucket.download_file(obj.key, target)\n",
    "        \n",
    "        \n",
    "download_s3_folder(s3_bucket_name, s3_directory_path, ADMIRER_DL_DATA_DIRNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find {ADMIRER_DL_DATA_DIRNAME} | head -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelStudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring and connecting to the web server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"admirer@localhost\"\n",
    "password = \"moonshine\"\n",
    "\n",
    "%env LABEL_STUDIO_USERNAME={username}\n",
    "%env LABEL_STUDIO_PASSWORD={password}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = ngrok.conf.DEFAULT_NGROK_CONFIG_PATH\n",
    "config_file_exists =  os.path.exists(config_file)\n",
    "config_file_contents = !cat {config_file}\n",
    "\n",
    "auth_token_found = config_file_exists \\\n",
    "    and config_file_contents \\\n",
    "    and \"authtoken\" in config_file_contents[0] \\\n",
    "    and \": exit\" not in config_file_contents  # state if interrupted\n",
    "\n",
    "if not auth_token_found:\n",
    "    print(\"Enter your ngrok auth token, which can be copied from https://dashboard.ngrok.com/auth\")\n",
    "    !ngrok authtoken {getpass.getpass()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_STUDIO_PORT = 8081\n",
    "%env LABEL_STUDIO_PORT={LABEL_STUDIO_PORT}\n",
    "\n",
    "https_tunnel = ngrok.connect(LABEL_STUDIO_PORT, bind_tls=True)\n",
    "print(https_tunnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 -m venv label-env\n",
    "# conda deactivate\n",
    "# source label-env/bin/activate\n",
    "# pip install -qqq label-studio\n",
    "# export LABEL_STUDIO_PORT=8081\n",
    "# label-studio start --port=$LABEL_STUDIO_PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(https_tunnel.public_url)\n",
    "print(\"u:\", username)\n",
    "print(\"p:\", password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "img_urls = []\n",
    "for person_idx in range(1, 104):\n",
    "    for image_idx in range(1, 13):\n",
    "        img_urls.append(f\"{s3_url}/{str(person_idx).zfill(3)}_{str(image_idx).zfill(2)}.png\")\n",
    "\n",
    "df = pd.DataFrame(img_urls, columns=[\"webcam\"])\n",
    "df.to_csv(str(ADMIRER_RAW_DATA_DIRNAME / \"manifest.csv\"), index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ADMIRER_RAW_DATA_DIRNAME / \"manifest.csv\")\n",
    "!cat {ADMIRER_RAW_DATA_DIRNAME}/manifest.csv | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teardown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deactivate\n",
    "# conda activate admirer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great Expectations + ZenML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ZenML Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderParameters(BaseParameters):\n",
    "    reference_data: bool = True\n",
    "\n",
    "@step\n",
    "def importer(\n",
    "        params: DataLoaderParameters,\n",
    ") -> Output(dataset=pd.DataFrame, condition=bool):\n",
    "    # Load labeled projects\n",
    "    admirer_pica_path = \"data/raw/admirer-pica/admirer-pica.json\"\n",
    "    df = pd.read_json(admirer_pica_path)\n",
    "    dataset = df[:5]\n",
    "    return dataset, params.reference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a builtin Great Expectations data profiling step\n",
    "ge_profiler_params = GreatExpectationsProfilerParameters(\n",
    "    expectation_suite_name=\"admirer-pica\",\n",
    "    data_asset_name=\"admirer-pica_test_df\",\n",
    ")\n",
    "ge_profiler_step = GreatExpectationsProfilerStep(params=ge_profiler_params)\n",
    "\n",
    "\n",
    "# instantiate a builtin Great Expectations data validation step\n",
    "ge_validator_params = GreatExpectationsValidatorParameters(\n",
    "    expectation_suite_name=\"admirer-pica\",\n",
    "    data_asset_name=\"admirer-pica_test_df\",\n",
    ")\n",
    "ge_validator_step = GreatExpectationsValidatorStep(params=ge_validator_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def analyze_result(\n",
    "    result: CheckpointResult,\n",
    ") -> str:\n",
    "    \"\"\"Analyze the Great Expectations validation result and return a true/false value indicating\n",
    "    whether it passed or failed.\"\"\"\n",
    "    step_env = cast(StepEnvironment, Environment()[STEP_ENVIRONMENT_NAME])\n",
    "    pipeline_name = step_env.pipeline_name\n",
    "    pipeline_run_id = step_env.pipeline_run_id\n",
    "    step_name = step_env.step_name\n",
    "    pipeline_context = f\"Pipeline {pipeline_name}, with run {pipeline_run_id}, in step {step_name} produced the following output:\\n\\n\"\n",
    "    if result.success:\n",
    "        message = pipeline_context + \"Great Expectations data validation was successful!\"\n",
    "    else:\n",
    "        message = pipeline_context + \"Great Expectations data validation failed!\"\n",
    "    print(message)\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ZenML Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_settings = DockerSettings(required_integrations=[GREAT_EXPECTATIONS])\n",
    "\n",
    "@pipeline(enable_cache=False, settings={\"docker\": docker_settings})\n",
    "def profiling_pipeline(\n",
    "    importer, profiler\n",
    "):\n",
    "    \"\"\"Data profiling pipeline for Great Expectations.\n",
    "\n",
    "    The pipeline imports a reference dataset from a source then uses the builtin\n",
    "    Great Expectations profiler step to generate an expectation suite (i.e.\n",
    "    validation rules) inferred from the schema and statistical properties of the\n",
    "    reference dataset.\n",
    "\n",
    "    Args:\n",
    "        importer: reference data importer step\n",
    "        profiler: data profiler step\n",
    "    \"\"\"\n",
    "    dataset, _ = importer()\n",
    "    profiler(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(enable_cache=False, settings={\"docker\": docker_settings})\n",
    "def validation_pipeline(\n",
    "    importer, validator, checker\n",
    "):\n",
    "    \"\"\"Data validation pipeline for Great Expectations.\n",
    "\n",
    "    The pipeline imports a test data from a source, then uses the builtin\n",
    "    Great Expectations data validation step to validate the dataset against\n",
    "    the expectation suite generated in the profiling pipeline.\n",
    "\n",
    "    Args:\n",
    "        importer: test data importer step\n",
    "        validator: dataset validation step\n",
    "        checker: checks the validation results\n",
    "    \"\"\"\n",
    "    dataset, condition = importer()\n",
    "    results = validator(dataset, condition)\n",
    "    message = checker(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiling_pipeline(\n",
    "    importer=importer(params=DataLoaderParameters(reference_data=True)),\n",
    "    profiler=ge_profiler_step,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_pipeline(\n",
    "    importer=importer(params=DataLoaderParameters(reference_data=True)),\n",
    "    validator=ge_validator_step,\n",
    "    checker=analyze_result(),\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post execution workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_pipeline_visualizer(name: str):\n",
    "\n",
    "    from zenml.integrations.dash.visualizers.pipeline_run_lineage_visualizer import (\n",
    "        PipelineRunLineageVisualizer,\n",
    "    )\n",
    "\n",
    "    latest_run = get_pipeline(name).runs[-1]\n",
    "    PipelineRunLineageVisualizer().visualize(latest_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(pipeline_name: str, step_name: str) -> None:\n",
    "    pipeline = get_pipeline(pipeline_name)\n",
    "    last_run = pipeline.runs[-1]\n",
    "    step = last_run.get_step(step=step_name)\n",
    "    GreatExpectationsVisualizer().visualize(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_pipeline_visualizer(\"profiling_pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_pipeline_visualizer(\"validation_pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_results(\"profiling_pipeline\", \"profiler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_results(\"validation_pipeline\", \"validator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serve and Deploy\n",
    "- Local/Local \n",
    "- Cloud Server/Cloud Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_img = \"question_answer/tests/support/images/img.jpg\"\n",
    "example_question = \"question_answer/tests/support/questions/question.txt\"\n",
    "\n",
    "print(qa.predict(example_img, example_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontend = app.make_frontend(qa.predict, flagging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontend.launch(share=True, width=\"100%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env API_URL={frontend.share_url + \"/api\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, = ! \\\n",
    "  (echo -n '{ \"data\": [\"data:image/jpg;base64,'$(base64 -w0 -i question_answer/tests/support/images/img.jpg)'\", \"data:question/str;str,'$(cat question_answer/tests/support/questions/question.txt)'\"] }') \\\n",
    "  | curl -s -X POST \"${API_URL}/predict\" -H 'Content-Type: application/json' -d @-\n",
    "  \n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.loads(response)[\"data\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontend.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serverless Backend (AWS Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build container image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LAMBDA_NAME\"] = \"admirer-backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -t $LAMBDA_NAME . --file api_serverless/Dockerfile #--no-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export LAMBDA_NAME=admirer-backend\n",
    "# docker run -p 9000:8080 $LAMBDA_NAME\\:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -XPOST \\\n",
    "  \"http://localhost:9000/2015-03-31/functions/function/invocations\" \\\n",
    "  -d '{\"image_url\": \"question_answer/tests/support/images/img.jpg\", \"question\": \"What color is my hair\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to the container registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_account_id, = !aws sts get-caller-identity \\\n",
    "  --query \"Account\"\n",
    "aws_region, = !aws configure get region \n",
    "\n",
    "os.environ[\"AWS_REGION\"] = aws_region\n",
    "os.environ[\"AWS_ACCOUNT_ID\"] = aws_account_id.strip('\"')\n",
    "\n",
    "!echo $AWS_ACCOUNT_ID\n",
    "!echo $AWS_REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ECR_URI\"] = \".\".join(\n",
    "    [os.environ[\"AWS_ACCOUNT_ID\"], \"dkr\", \"ecr\", os.environ[\"AWS_REGION\"], \"amazonaws.com\"])\n",
    "\n",
    "!echo $ECR_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws ecr get-login-password --region $AWS_REGION \\\n",
    "  | docker login --username AWS --password-stdin $ECR_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws ecr create-repository \\\n",
    "  --repository-name $LAMBDA_NAME \\\n",
    "  --image-scanning-configuration scanOnPush=true --image-tag-mutability MUTABLE \\\n",
    "  | jq -C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"IMAGE_URI\"] = \"/\".join([os.environ[\"ECR_URI\"], os.environ[\"LAMBDA_NAME\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag $LAMBDA_NAME\\:latest $IMAGE_URI\\:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker push $IMAGE_URI\\:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LAMBDA_ROLE_NAME\"] = \"lambda-role\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws iam create-role \\\n",
    "  --role-name $LAMBDA_ROLE_NAME \\\n",
    "  --assume-role-policy-document '{\"Version\": \"2012-10-17\", \"Statement\": [{\"Effect\": \"Allow\", \"Principal\": {\"Service\": \"lambda.amazonaws.com\"}, \"Action\": \"sts:AssumeRole\"}]}' \\\n",
    "  | jq -C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_role_arn, = !aws iam get-role --role-name $LAMBDA_ROLE_NAME --output json | jq -r '.Role.Arn'\n",
    "lambda_role_arn = lambda_role_arn.strip('\"')\n",
    "\n",
    "os.environ[\"LAMBDA_ROLE_ARN\"] = lambda_role_arn\n",
    "!echo $LAMBDA_ROLE_ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow this IAM role to execute Lambdas\n",
    "!aws iam attach-role-policy \\\n",
    "  --role-name $LAMBDA_ROLE_NAME \\\n",
    "  --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow this IAM role to write to logs -- required and also important for debugging Lambdas\n",
    "!aws iam attach-role-policy \\\n",
    "  --role-name $LAMBDA_ROLE_NAME \\\n",
    "  --policy-arn arn:aws:iam::aws:policy/AWSXRayDaemonWriteAccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws lambda create-function \\\n",
    "  --function-name $LAMBDA_NAME \\\n",
    "  --region $AWS_REGION \\\n",
    "  --package-type Image \\\n",
    "  --code ImageUri=$IMAGE_URI:latest \\\n",
    "  --role $LAMBDA_ROLE_ARN | jq -C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws lambda update-function-configuration \\\n",
    "   --function-name $LAMBDA_NAME \\\n",
    "   --region $AWS_REGION \\\n",
    "   --timeout 60 \\\n",
    "   --memory-size 10240 | jq -C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws lambda invoke \\\n",
    "  --function-name $LAMBDA_NAME \\\n",
    "  --invocation-type RequestResponse \\\n",
    "  --payload '{\"image_url\": \"question_answer/tests/support/images/img.jpg\", \"question\": \"What color is my hair\"}' \\\n",
    "  --cli-binary-format raw-in-base64-out lambda.out | jq -C\n",
    "\n",
    "!cat lambda.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add an HTTP endpoint with a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws lambda create-function-url-config \\\n",
    "  --function-name $LAMBDA_NAME \\\n",
    "  --auth-type NONE \\\n",
    "  --cors '{\"AllowOrigins\": [\"*\"], \"AllowCredentials\": false}' \\\n",
    "  | jq -C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Careful here!!!\n",
    "# \"\"\"\n",
    "!aws lambda add-permission \\\n",
    " --function-name $LAMBDA_NAME \\\n",
    " --action lambda:invokeFunctionUrl \\\n",
    " --statement-id \"open-access\" \\\n",
    " --principal \"*\" \\\n",
    " --function-url-auth-type NONE | jq -C\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_url, = !aws lambda get-function-url-config --function-name $LAMBDA_NAME | jq .FunctionUrl\n",
    "lambda_url = lambda_url.strip('\"')\n",
    "\n",
    "lambda_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"question_answer/tests/support/images/img.jpg\"\n",
    "question = \"What color is my hair\"\n",
    "\n",
    "headers = {\"Content-type\": \"application/json\"}\n",
    "payload = json.dumps({\"image_url\": image_url, \"question\": question})\n",
    "\n",
    "response = requests.post(\n",
    "  lambda_url, data=payload, headers=headers)\n",
    "pred = response.json()[\"pred\"]\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect AWS with Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serverless_backend = app.PredictorBackend(url=lambda_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontend_serverless_backend = app.make_frontend(serverless_backend.run, flagging=True)\n",
    "frontend_serverless_backend.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontend_serverless_backend.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving through Ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontend = frontend #frontend_serverless_backend\n",
    "frontend.local_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST {frontend.local_url}api/predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = ngrok.conf.DEFAULT_NGROK_CONFIG_PATH\n",
    "config_file_exists =  os.path.exists(config_file)\n",
    "config_file_contents = !cat {config_file}\n",
    "\n",
    "auth_token_found = config_file_exists \\\n",
    "    and config_file_contents \\\n",
    "    and \"authtoken\" in config_file_contents[0] \\\n",
    "    and \": exit\" not in config_file_contents  # state if interrupted\n",
    "\n",
    "if not auth_token_found:\n",
    "    print(\"Enter your ngrok auth token, which can be copied from https://dashboard.ngrok.com/auth\")\n",
    "    !ngrok authtoken {getpass.getpass()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADMIRER_PORT = frontend.server_port\n",
    "ADMIRER_PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https_tunnel = ngrok.connect(ADMIRER_PORT, bind_tls=True)\n",
    "# print(https_tunnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Testing with Locust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the load test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!locust --locustfile=locust_http_user.py \\\n",
    "  --headless \\\n",
    "  --users=10 \\\n",
    "  --spawn-rate=1 \\\n",
    "  --run-time=2m \\\n",
    "  --host=https://joiajq6syp65ueonto4mswttzu0apfbi.lambda-url.us-west-1.on.aws \\\n",
    "  --html=locust_report.html \\\n",
    "  --csv=locust_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh locust_report*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.HTML(\"locust_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing load test data programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"locust_report_stats_history.csv\"\n",
    "results = pd.read_csv(csv_path)\n",
    "results[\"Timestamp\"] = pd.to_datetime(results[\"Timestamp\"], unit=\"s\")\n",
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_columns = [\"Total Request Count\", \"Total Failure Count\", \"User Count\"]\n",
    "results.plot(x=\"Timestamp\", y=request_columns, subplots=True, sharey=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_columns = [\"Total Average Response Time\", \"Total Max Response Time\"]\n",
    "results.plot(x=\"Timestamp\", y=response_columns);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby(\"Total Median Response Time\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('admirer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c4de3d17692a4fce36158e1e6b4cc65d2c1c1dbb8a445fcd77e7a07c1299f79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
